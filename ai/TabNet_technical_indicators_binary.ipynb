{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import * \n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import requests\n",
    "import pandas_ta as ta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import talib\n",
    "import json \n",
    "import ccxt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('ByBit_BTCUSDT.json') as f:\n",
    "    d = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585141200000</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>6745.5</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>449.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585144800000</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>258.831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1       2       3       4        5\n",
       "0  1585130400000  6500.0  6591.5  6500.0  6591.5    0.004\n",
       "1  1585134000000  6591.5  6628.5  6457.5  6511.5  438.873\n",
       "2  1585137600000  6511.5  6588.5  6502.0  6583.5  529.318\n",
       "3  1585141200000  6583.5  6745.5  6562.0  6585.0  449.162\n",
       "4  1585144800000  6585.0  6640.0  6516.0  6590.0  258.831"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp    open    high     low   close   volume\n",
       "0  1585130400000  6500.0  6591.5  6500.0  6591.5    0.004\n",
       "1  1585134000000  6591.5  6628.5  6457.5  6511.5  438.873\n",
       "2  1585137600000  6511.5  6588.5  6502.0  6583.5  529.318"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={0:\"timestamp\",\n",
    "                        1:\"open\",\n",
    "                        2:\"high\",\n",
    "                        3:\"low\",\n",
    "                        4:\"close\",\n",
    "                        5:\"volume\"})\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df): \n",
    "    bybit = ccxt.bybit() \n",
    "    dates = df['timestamp'].values \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)): \n",
    "        date_string = bybit.iso8601(int(dates[i])) \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string) \n",
    "    df['datetime'] = timestamp \n",
    "    df = df.drop(columns={'timestamp'})\n",
    "    return df\n",
    "\n",
    "df = process(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16870/16870 [00:08<00:00, 2069.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Days</th>\n",
       "      <th>Months</th>\n",
       "      <th>Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     open    high     low   close   volume             datetime  Hours  Days  \\\n",
       "0  6500.0  6591.5  6500.0  6591.5    0.004  2020-03-25 10:00:00     10    25   \n",
       "1  6591.5  6628.5  6457.5  6511.5  438.873  2020-03-25 11:00:00     11    25   \n",
       "2  6511.5  6588.5  6502.0  6583.5  529.318  2020-03-25 12:00:00     12    25   \n",
       "\n",
       "   Months  Years  \n",
       "0       3   2020  \n",
       "1       3   2020  \n",
       "2       3   2020  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours = []\n",
    "days = [] \n",
    "months = [] \n",
    "years = [] \n",
    "for dt in tqdm(df['datetime']):\n",
    "    hour = pd.to_datetime(dt).hour \n",
    "    day = pd.to_datetime(dt).day \n",
    "    month = pd.to_datetime(dt).month \n",
    "    year = pd.to_datetime(dt).year \n",
    "    hours.append(hour) \n",
    "    days.append(day) \n",
    "    months.append(month)\n",
    "    years.append(year) \n",
    "\n",
    "df['Hours'] = hours\n",
    "df['Days'] = days \n",
    "df['Months'] = months \n",
    "df['Years'] = years \n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets = [] \n",
    "close = df['close'].values\n",
    "# 0: long, 1: short, 2: hold \n",
    "for i in range(len(close)-1):\n",
    "    ret = (close[i+1] - close[i]) / close[i] \n",
    "    if ret > -0.002 and ret < 0.002:\n",
    "        targets.append(2) \n",
    "    elif ret <= -0.002:\n",
    "        targets.append(1) \n",
    "    elif ret >= 0.002: \n",
    "        targets.append(0) \n",
    "        \n",
    "sns.countplot(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Days</th>\n",
       "      <th>Months</th>\n",
       "      <th>Years</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     open    high     low   close   volume             datetime  Hours  Days  \\\n",
       "0  6500.0  6591.5  6500.0  6591.5    0.004  2020-03-25 10:00:00     10    25   \n",
       "1  6591.5  6628.5  6457.5  6511.5  438.873  2020-03-25 11:00:00     11    25   \n",
       "2  6511.5  6588.5  6502.0  6583.5  529.318  2020-03-25 12:00:00     12    25   \n",
       "\n",
       "   Months  Years  target  \n",
       "0       3   2020     1.0  \n",
       "1       3   2020     0.0  \n",
       "2       3   2020     2.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.append(None) \n",
    "\n",
    "df['target'] = targets \n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13966, 11), (1552, 11), (1351, 11))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna() \n",
    "\n",
    "train_df = df[df['Years'] != 2022] \n",
    "test_df = df[df['Years'] == 2022] \n",
    "\n",
    "train_size = int(train_df.shape[0] * 0.9) \n",
    "val_df = train_df.iloc[train_size:, :] \n",
    "train_df = train_df.iloc[:train_size,:] \n",
    "\n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns={'datetime','Years'}) \n",
    "val_df = val_df.drop(columns={'datetime', 'Years'}) \n",
    "test_df = test_df.drop(columns={'datetime', 'Years'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = []\n",
    "for col in train_df.columns:\n",
    "    if col != 'target':\n",
    "        input_features.append(col) \n",
    "        \n",
    "X_train = train_df[input_features].values\n",
    "Y_train = train_df['target'].values \n",
    "Y_train = Y_train.reshape((-1,1))\n",
    "\n",
    "X_val = val_df[input_features].values\n",
    "Y_val = val_df['target'].values \n",
    "Y_val = Y_val.reshape((-1,1))\n",
    "\n",
    "X_test = test_df[input_features].values\n",
    "Y_test = test_df['target'].values \n",
    "Y_test = Y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 1.15189 | val_0_accuracy: 0.3183  | val_0_balanced_accuracy: 0.31578 |  0:00:01s\n",
      "epoch 1  | loss: 1.0684  | val_0_accuracy: 0.3357  | val_0_balanced_accuracy: 0.33589 |  0:00:02s\n",
      "epoch 2  | loss: 1.06152 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.32792 |  0:00:03s\n",
      "epoch 3  | loss: 1.05985 | val_0_accuracy: 0.34987 | val_0_balanced_accuracy: 0.34691 |  0:00:04s\n",
      "epoch 4  | loss: 1.05761 | val_0_accuracy: 0.32861 | val_0_balanced_accuracy: 0.32581 |  0:00:05s\n",
      "epoch 5  | loss: 1.05554 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.34288 |  0:00:06s\n",
      "epoch 6  | loss: 1.05405 | val_0_accuracy: 0.35438 | val_0_balanced_accuracy: 0.35081 |  0:00:07s\n",
      "epoch 7  | loss: 1.05335 | val_0_accuracy: 0.34665 | val_0_balanced_accuracy: 0.34371 |  0:00:08s\n",
      "epoch 8  | loss: 1.05353 | val_0_accuracy: 0.34665 | val_0_balanced_accuracy: 0.34353 |  0:00:09s\n",
      "epoch 9  | loss: 1.05077 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.34352 |  0:00:10s\n",
      "epoch 10 | loss: 1.05149 | val_0_accuracy: 0.34601 | val_0_balanced_accuracy: 0.33053 |  0:00:11s\n",
      "epoch 11 | loss: 1.05116 | val_0_accuracy: 0.34923 | val_0_balanced_accuracy: 0.33357 |  0:00:12s\n",
      "epoch 12 | loss: 1.04924 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.33286 |  0:00:13s\n",
      "epoch 13 | loss: 1.04911 | val_0_accuracy: 0.34923 | val_0_balanced_accuracy: 0.34692 |  0:00:14s\n",
      "epoch 14 | loss: 1.04855 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36206 |  0:00:15s\n",
      "epoch 15 | loss: 1.04748 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.33781 |  0:00:16s\n",
      "epoch 16 | loss: 1.0461  | val_0_accuracy: 0.34214 | val_0_balanced_accuracy: 0.34418 |  0:00:17s\n",
      "epoch 17 | loss: 1.04534 | val_0_accuracy: 0.3576  | val_0_balanced_accuracy: 0.35992 |  0:00:18s\n",
      "epoch 18 | loss: 1.04444 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.34303 |  0:00:19s\n",
      "epoch 19 | loss: 1.04358 | val_0_accuracy: 0.34536 | val_0_balanced_accuracy: 0.3368  |  0:00:20s\n",
      "epoch 20 | loss: 1.04222 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.33817 |  0:00:21s\n",
      "epoch 21 | loss: 1.04215 | val_0_accuracy: 0.36405 | val_0_balanced_accuracy: 0.37308 |  0:00:22s\n",
      "epoch 22 | loss: 1.04326 | val_0_accuracy: 0.3357  | val_0_balanced_accuracy: 0.33698 |  0:00:23s\n",
      "epoch 23 | loss: 1.04334 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.34436 |  0:00:24s\n",
      "epoch 24 | loss: 1.04415 | val_0_accuracy: 0.34601 | val_0_balanced_accuracy: 0.35416 |  0:00:25s\n",
      "epoch 25 | loss: 1.04433 | val_0_accuracy: 0.33827 | val_0_balanced_accuracy: 0.34093 |  0:00:26s\n",
      "epoch 26 | loss: 1.0436  | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.35783 |  0:00:26s\n",
      "epoch 27 | loss: 1.04138 | val_0_accuracy: 0.3518  | val_0_balanced_accuracy: 0.35448 |  0:00:27s\n",
      "epoch 28 | loss: 1.04063 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.35386 |  0:00:28s\n",
      "epoch 29 | loss: 1.0434  | val_0_accuracy: 0.35438 | val_0_balanced_accuracy: 0.35571 |  0:00:29s\n",
      "epoch 30 | loss: 1.04284 | val_0_accuracy: 0.34085 | val_0_balanced_accuracy: 0.35009 |  0:00:30s\n",
      "epoch 31 | loss: 1.04358 | val_0_accuracy: 0.36082 | val_0_balanced_accuracy: 0.36921 |  0:00:31s\n",
      "epoch 32 | loss: 1.04062 | val_0_accuracy: 0.37887 | val_0_balanced_accuracy: 0.38077 |  0:00:32s\n",
      "epoch 33 | loss: 1.04324 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.35798 |  0:00:33s\n",
      "epoch 34 | loss: 1.04307 | val_0_accuracy: 0.34214 | val_0_balanced_accuracy: 0.34615 |  0:00:34s\n",
      "epoch 35 | loss: 1.04107 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.35706 |  0:00:35s\n",
      "epoch 36 | loss: 1.04102 | val_0_accuracy: 0.34021 | val_0_balanced_accuracy: 0.34088 |  0:00:36s\n",
      "epoch 37 | loss: 1.04225 | val_0_accuracy: 0.34923 | val_0_balanced_accuracy: 0.35356 |  0:00:37s\n",
      "epoch 38 | loss: 1.04181 | val_0_accuracy: 0.36276 | val_0_balanced_accuracy: 0.36962 |  0:00:38s\n",
      "epoch 39 | loss: 1.04121 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.35072 |  0:00:39s\n",
      "epoch 40 | loss: 1.04101 | val_0_accuracy: 0.33827 | val_0_balanced_accuracy: 0.33864 |  0:00:39s\n",
      "epoch 41 | loss: 1.04187 | val_0_accuracy: 0.3518  | val_0_balanced_accuracy: 0.35192 |  0:00:40s\n",
      "epoch 42 | loss: 1.04197 | val_0_accuracy: 0.34407 | val_0_balanced_accuracy: 0.35121 |  0:00:41s\n",
      "epoch 43 | loss: 1.04327 | val_0_accuracy: 0.35116 | val_0_balanced_accuracy: 0.34836 |  0:00:42s\n",
      "epoch 44 | loss: 1.04147 | val_0_accuracy: 0.34601 | val_0_balanced_accuracy: 0.34656 |  0:00:43s\n",
      "epoch 45 | loss: 1.03979 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.35776 |  0:00:44s\n",
      "epoch 46 | loss: 1.03848 | val_0_accuracy: 0.34407 | val_0_balanced_accuracy: 0.34413 |  0:00:45s\n",
      "epoch 47 | loss: 1.04148 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.35356 |  0:00:46s\n",
      "epoch 48 | loss: 1.03975 | val_0_accuracy: 0.35889 | val_0_balanced_accuracy: 0.36776 |  0:00:47s\n",
      "epoch 49 | loss: 1.03996 | val_0_accuracy: 0.34085 | val_0_balanced_accuracy: 0.34908 |  0:00:48s\n",
      "epoch 50 | loss: 1.03973 | val_0_accuracy: 0.34278 | val_0_balanced_accuracy: 0.34175 |  0:00:49s\n",
      "epoch 51 | loss: 1.0391  | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36148 |  0:00:50s\n",
      "epoch 52 | loss: 1.03902 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.34857 |  0:00:50s\n",
      "epoch 53 | loss: 1.038   | val_0_accuracy: 0.33698 | val_0_balanced_accuracy: 0.33833 |  0:00:51s\n",
      "epoch 54 | loss: 1.04042 | val_0_accuracy: 0.34536 | val_0_balanced_accuracy: 0.34294 |  0:00:52s\n",
      "epoch 55 | loss: 1.03806 | val_0_accuracy: 0.34149 | val_0_balanced_accuracy: 0.34808 |  0:00:53s\n",
      "epoch 56 | loss: 1.03849 | val_0_accuracy: 0.33892 | val_0_balanced_accuracy: 0.34662 |  0:00:54s\n",
      "epoch 57 | loss: 1.03802 | val_0_accuracy: 0.33827 | val_0_balanced_accuracy: 0.34262 |  0:00:55s\n",
      "epoch 58 | loss: 1.04029 | val_0_accuracy: 0.33505 | val_0_balanced_accuracy: 0.33818 |  0:00:56s\n",
      "epoch 59 | loss: 1.03751 | val_0_accuracy: 0.3518  | val_0_balanced_accuracy: 0.35791 |  0:00:57s\n",
      "epoch 60 | loss: 1.04098 | val_0_accuracy: 0.3576  | val_0_balanced_accuracy: 0.36256 |  0:00:58s\n",
      "epoch 61 | loss: 1.04119 | val_0_accuracy: 0.3576  | val_0_balanced_accuracy: 0.36233 |  0:00:59s\n",
      "epoch 62 | loss: 1.04063 | val_0_accuracy: 0.33763 | val_0_balanced_accuracy: 0.34148 |  0:01:00s\n",
      "epoch 63 | loss: 1.04051 | val_0_accuracy: 0.34536 | val_0_balanced_accuracy: 0.3478  |  0:01:01s\n",
      "epoch 64 | loss: 1.03907 | val_0_accuracy: 0.33827 | val_0_balanced_accuracy: 0.33963 |  0:01:02s\n",
      "epoch 65 | loss: 1.03987 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.35579 |  0:01:03s\n",
      "epoch 66 | loss: 1.03906 | val_0_accuracy: 0.37887 | val_0_balanced_accuracy: 0.38418 |  0:01:03s\n",
      "epoch 67 | loss: 1.04125 | val_0_accuracy: 0.36018 | val_0_balanced_accuracy: 0.36739 |  0:01:04s\n",
      "epoch 68 | loss: 1.04021 | val_0_accuracy: 0.35696 | val_0_balanced_accuracy: 0.35579 |  0:01:05s\n",
      "epoch 69 | loss: 1.04015 | val_0_accuracy: 0.35954 | val_0_balanced_accuracy: 0.36656 |  0:01:06s\n",
      "epoch 70 | loss: 1.04135 | val_0_accuracy: 0.36082 | val_0_balanced_accuracy: 0.36057 |  0:01:07s\n",
      "epoch 71 | loss: 1.0409  | val_0_accuracy: 0.3576  | val_0_balanced_accuracy: 0.36373 |  0:01:08s\n",
      "epoch 72 | loss: 1.04145 | val_0_accuracy: 0.35889 | val_0_balanced_accuracy: 0.36241 |  0:01:09s\n",
      "epoch 73 | loss: 1.03939 | val_0_accuracy: 0.36662 | val_0_balanced_accuracy: 0.36435 |  0:01:10s\n",
      "epoch 74 | loss: 1.03931 | val_0_accuracy: 0.35245 | val_0_balanced_accuracy: 0.35976 |  0:01:11s\n",
      "epoch 75 | loss: 1.03867 | val_0_accuracy: 0.36082 | val_0_balanced_accuracy: 0.36285 |  0:01:12s\n",
      "epoch 76 | loss: 1.0399  | val_0_accuracy: 0.34987 | val_0_balanced_accuracy: 0.35692 |  0:01:12s\n",
      "epoch 77 | loss: 1.04012 | val_0_accuracy: 0.34021 | val_0_balanced_accuracy: 0.3402  |  0:01:13s\n",
      "epoch 78 | loss: 1.03863 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.35058 |  0:01:14s\n",
      "epoch 79 | loss: 1.04051 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.36369 |  0:01:15s\n",
      "epoch 80 | loss: 1.04072 | val_0_accuracy: 0.35245 | val_0_balanced_accuracy: 0.35974 |  0:01:16s\n",
      "epoch 81 | loss: 1.03945 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36093 |  0:01:17s\n",
      "epoch 82 | loss: 1.0406  | val_0_accuracy: 0.35438 | val_0_balanced_accuracy: 0.36218 |  0:01:18s\n",
      "epoch 83 | loss: 1.04008 | val_0_accuracy: 0.34987 | val_0_balanced_accuracy: 0.35749 |  0:01:19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84 | loss: 1.03861 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.35546 |  0:01:20s\n",
      "epoch 85 | loss: 1.04026 | val_0_accuracy: 0.34665 | val_0_balanced_accuracy: 0.35408 |  0:01:21s\n",
      "epoch 86 | loss: 1.03909 | val_0_accuracy: 0.33892 | val_0_balanced_accuracy: 0.34608 |  0:01:22s\n",
      "epoch 87 | loss: 1.04006 | val_0_accuracy: 0.34987 | val_0_balanced_accuracy: 0.35736 |  0:01:23s\n",
      "epoch 88 | loss: 1.03922 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.356   |  0:01:24s\n",
      "epoch 89 | loss: 1.0387  | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.36139 |  0:01:25s\n",
      "epoch 90 | loss: 1.03854 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36078 |  0:01:25s\n",
      "epoch 91 | loss: 1.03936 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36074 |  0:01:26s\n",
      "epoch 92 | loss: 1.03911 | val_0_accuracy: 0.36534 | val_0_balanced_accuracy: 0.37142 |  0:01:27s\n",
      "epoch 93 | loss: 1.03816 | val_0_accuracy: 0.36985 | val_0_balanced_accuracy: 0.36662 |  0:01:28s\n",
      "epoch 94 | loss: 1.03701 | val_0_accuracy: 0.35052 | val_0_balanced_accuracy: 0.35032 |  0:01:29s\n",
      "epoch 95 | loss: 1.03669 | val_0_accuracy: 0.36469 | val_0_balanced_accuracy: 0.37234 |  0:01:30s\n",
      "epoch 96 | loss: 1.03817 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.35545 |  0:01:31s\n",
      "epoch 97 | loss: 1.03744 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.36302 |  0:01:32s\n",
      "epoch 98 | loss: 1.04007 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.36257 |  0:01:33s\n",
      "epoch 99 | loss: 1.03703 | val_0_accuracy: 0.34343 | val_0_balanced_accuracy: 0.3455  |  0:01:34s\n",
      "epoch 100| loss: 1.03995 | val_0_accuracy: 0.34987 | val_0_balanced_accuracy: 0.3515  |  0:01:35s\n",
      "epoch 101| loss: 1.04014 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.35559 |  0:01:36s\n",
      "epoch 102| loss: 1.03946 | val_0_accuracy: 0.3692  | val_0_balanced_accuracy: 0.36828 |  0:01:37s\n",
      "epoch 103| loss: 1.03742 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.35287 |  0:01:38s\n",
      "epoch 104| loss: 1.03804 | val_0_accuracy: 0.34729 | val_0_balanced_accuracy: 0.35485 |  0:01:38s\n",
      "epoch 105| loss: 1.03944 | val_0_accuracy: 0.3634  | val_0_balanced_accuracy: 0.36859 |  0:01:39s\n",
      "epoch 106| loss: 1.03799 | val_0_accuracy: 0.36856 | val_0_balanced_accuracy: 0.37548 |  0:01:40s\n",
      "epoch 107| loss: 1.03645 | val_0_accuracy: 0.36147 | val_0_balanced_accuracy: 0.36977 |  0:01:41s\n",
      "epoch 108| loss: 1.03683 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.35621 |  0:01:42s\n",
      "epoch 109| loss: 1.03852 | val_0_accuracy: 0.33827 | val_0_balanced_accuracy: 0.34546 |  0:01:43s\n",
      "epoch 110| loss: 1.03716 | val_0_accuracy: 0.35889 | val_0_balanced_accuracy: 0.36349 |  0:01:44s\n",
      "epoch 111| loss: 1.03634 | val_0_accuracy: 0.37436 | val_0_balanced_accuracy: 0.38143 |  0:01:45s\n",
      "epoch 112| loss: 1.03723 | val_0_accuracy: 0.36985 | val_0_balanced_accuracy: 0.37843 |  0:01:46s\n",
      "epoch 113| loss: 1.03808 | val_0_accuracy: 0.35954 | val_0_balanced_accuracy: 0.36783 |  0:01:47s\n",
      "epoch 114| loss: 1.038   | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36402 |  0:01:47s\n",
      "epoch 115| loss: 1.03781 | val_0_accuracy: 0.35245 | val_0_balanced_accuracy: 0.36047 |  0:01:48s\n",
      "epoch 116| loss: 1.03549 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36336 |  0:01:49s\n",
      "epoch 117| loss: 1.0358  | val_0_accuracy: 0.34214 | val_0_balanced_accuracy: 0.34342 |  0:01:50s\n",
      "epoch 118| loss: 1.03553 | val_0_accuracy: 0.35696 | val_0_balanced_accuracy: 0.35916 |  0:01:51s\n",
      "epoch 119| loss: 1.03708 | val_0_accuracy: 0.34149 | val_0_balanced_accuracy: 0.34491 |  0:01:52s\n",
      "epoch 120| loss: 1.03552 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.36023 |  0:01:53s\n",
      "epoch 121| loss: 1.03592 | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.35275 |  0:01:54s\n",
      "epoch 122| loss: 1.03641 | val_0_accuracy: 0.36082 | val_0_balanced_accuracy: 0.36467 |  0:01:55s\n",
      "epoch 123| loss: 1.03549 | val_0_accuracy: 0.33892 | val_0_balanced_accuracy: 0.3402  |  0:01:56s\n",
      "epoch 124| loss: 1.0365  | val_0_accuracy: 0.35309 | val_0_balanced_accuracy: 0.36065 |  0:01:57s\n",
      "epoch 125| loss: 1.03407 | val_0_accuracy: 0.35052 | val_0_balanced_accuracy: 0.35182 |  0:01:58s\n",
      "epoch 126| loss: 1.03442 | val_0_accuracy: 0.33956 | val_0_balanced_accuracy: 0.3389  |  0:01:58s\n",
      "epoch 127| loss: 1.03452 | val_0_accuracy: 0.36534 | val_0_balanced_accuracy: 0.36637 |  0:01:59s\n",
      "epoch 128| loss: 1.03544 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.35566 |  0:02:00s\n",
      "epoch 129| loss: 1.03452 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36324 |  0:02:01s\n",
      "epoch 130| loss: 1.03471 | val_0_accuracy: 0.36276 | val_0_balanced_accuracy: 0.36444 |  0:02:02s\n",
      "epoch 131| loss: 1.03515 | val_0_accuracy: 0.33698 | val_0_balanced_accuracy: 0.33773 |  0:02:03s\n",
      "epoch 132| loss: 1.03441 | val_0_accuracy: 0.35889 | val_0_balanced_accuracy: 0.3645  |  0:02:04s\n",
      "epoch 133| loss: 1.03315 | val_0_accuracy: 0.34343 | val_0_balanced_accuracy: 0.34985 |  0:02:05s\n",
      "epoch 134| loss: 1.03449 | val_0_accuracy: 0.36211 | val_0_balanced_accuracy: 0.37019 |  0:02:06s\n",
      "epoch 135| loss: 1.0365  | val_0_accuracy: 0.35438 | val_0_balanced_accuracy: 0.35702 |  0:02:07s\n",
      "epoch 136| loss: 1.03347 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.35895 |  0:02:08s\n",
      "epoch 137| loss: 1.03548 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.3655  |  0:02:09s\n",
      "epoch 138| loss: 1.03682 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.36329 |  0:02:09s\n",
      "epoch 139| loss: 1.03482 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.35941 |  0:02:10s\n",
      "epoch 140| loss: 1.03344 | val_0_accuracy: 0.37178 | val_0_balanced_accuracy: 0.3758  |  0:02:11s\n",
      "epoch 141| loss: 1.03495 | val_0_accuracy: 0.37564 | val_0_balanced_accuracy: 0.38109 |  0:02:12s\n",
      "epoch 142| loss: 1.03567 | val_0_accuracy: 0.33505 | val_0_balanced_accuracy: 0.34011 |  0:02:13s\n",
      "epoch 143| loss: 1.03579 | val_0_accuracy: 0.33054 | val_0_balanced_accuracy: 0.33164 |  0:02:14s\n",
      "epoch 144| loss: 1.03555 | val_0_accuracy: 0.34472 | val_0_balanced_accuracy: 0.348   |  0:02:15s\n",
      "epoch 145| loss: 1.03483 | val_0_accuracy: 0.33441 | val_0_balanced_accuracy: 0.34166 |  0:02:16s\n",
      "epoch 146| loss: 1.03604 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36539 |  0:02:17s\n",
      "epoch 147| loss: 1.03413 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.35428 |  0:02:18s\n",
      "epoch 148| loss: 1.0353  | val_0_accuracy: 0.35696 | val_0_balanced_accuracy: 0.36008 |  0:02:19s\n",
      "epoch 149| loss: 1.03386 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36387 |  0:02:20s\n",
      "epoch 150| loss: 1.03403 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.36051 |  0:02:21s\n",
      "epoch 151| loss: 1.03389 | val_0_accuracy: 0.34794 | val_0_balanced_accuracy: 0.34308 |  0:02:21s\n",
      "epoch 152| loss: 1.03338 | val_0_accuracy: 0.35825 | val_0_balanced_accuracy: 0.36527 |  0:02:22s\n",
      "epoch 153| loss: 1.03218 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.3498  |  0:02:23s\n",
      "epoch 154| loss: 1.03562 | val_0_accuracy: 0.3634  | val_0_balanced_accuracy: 0.36625 |  0:02:24s\n",
      "epoch 155| loss: 1.0349  | val_0_accuracy: 0.34149 | val_0_balanced_accuracy: 0.34313 |  0:02:25s\n",
      "epoch 156| loss: 1.034   | val_0_accuracy: 0.36405 | val_0_balanced_accuracy: 0.36581 |  0:02:26s\n",
      "epoch 157| loss: 1.03347 | val_0_accuracy: 0.35631 | val_0_balanced_accuracy: 0.36022 |  0:02:27s\n",
      "epoch 158| loss: 1.03248 | val_0_accuracy: 0.34729 | val_0_balanced_accuracy: 0.34782 |  0:02:28s\n",
      "epoch 159| loss: 1.03513 | val_0_accuracy: 0.35374 | val_0_balanced_accuracy: 0.3584  |  0:02:29s\n",
      "epoch 160| loss: 1.03321 | val_0_accuracy: 0.35954 | val_0_balanced_accuracy: 0.36371 |  0:02:30s\n",
      "epoch 161| loss: 1.03378 | val_0_accuracy: 0.34858 | val_0_balanced_accuracy: 0.3483  |  0:02:31s\n",
      "epoch 162| loss: 1.03377 | val_0_accuracy: 0.36018 | val_0_balanced_accuracy: 0.36342 |  0:02:32s\n",
      "epoch 163| loss: 1.03549 | val_0_accuracy: 0.35567 | val_0_balanced_accuracy: 0.35729 |  0:02:33s\n",
      "epoch 164| loss: 1.03471 | val_0_accuracy: 0.36791 | val_0_balanced_accuracy: 0.37141 |  0:02:34s\n",
      "epoch 165| loss: 1.03744 | val_0_accuracy: 0.36727 | val_0_balanced_accuracy: 0.36939 |  0:02:35s\n",
      "epoch 166| loss: 1.03397 | val_0_accuracy: 0.34665 | val_0_balanced_accuracy: 0.35359 |  0:02:36s\n",
      "\n",
      "Early stopping occurred at epoch 166 with best_epoch = 66 and best_val_0_balanced_accuracy = 0.38418\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier \n",
    "\n",
    "clf = TabNetMultiTaskClassifier() \n",
    "\n",
    "clf.fit(\n",
    "    X_train, Y_train, \n",
    "    eval_set=[(X_val, Y_val)], \n",
    "    eval_metric = ['accuracy', 'balanced_accuracy'],\n",
    "    max_epochs = 500, \n",
    "    patience = 100 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.01110288675056\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_test)[0]\n",
    "cnt = 0 \n",
    "for i in range(len(Y_test)):\n",
    "    if float(prediction[i]) == Y_test[i]:\n",
    "        cnt += 1 \n",
    "        \n",
    "print(cnt / len(prediction) * 100)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16870/16870 [00:02<00:00, 7316.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day_of_weeks</th>\n",
       "      <th>Days</th>\n",
       "      <th>Months</th>\n",
       "      <th>Years</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     open    high     low   close   volume             datetime  Hours  \\\n",
       "0  6500.0  6591.5  6500.0  6591.5    0.004  2020-03-25 10:00:00     10   \n",
       "1  6591.5  6628.5  6457.5  6511.5  438.873  2020-03-25 11:00:00     11   \n",
       "2  6511.5  6588.5  6502.0  6583.5  529.318  2020-03-25 12:00:00     12   \n",
       "\n",
       "   Day_of_weeks  Days  Months  Years  target  \n",
       "0             2    25       3   2020     1.0  \n",
       "1             2    25       3   2020     0.0  \n",
       "2             2    25       3   2020     0.0  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ByBit_BTCUSDT.json') as f:\n",
    "    d = json.load(f)\n",
    "df = pd.DataFrame(d)\n",
    "df = df.rename(columns={0:\"timestamp\",\n",
    "                        1:\"open\",\n",
    "                        2:\"high\",\n",
    "                        3:\"low\",\n",
    "                        4:\"close\",\n",
    "                        5:\"volume\"})\n",
    "df = process(df)\n",
    "\n",
    "hours = []\n",
    "day_of_weeks = [] \n",
    "days = [] \n",
    "months = [] \n",
    "years = [] \n",
    "for dt in tqdm(df['datetime'], position=0, leave=True):\n",
    "    dtobj = pd.to_datetime(dt)\n",
    "    hour = dtobj.hour  \n",
    "    day_of_week = dtobj.dayofweek\n",
    "    day = dtobj.day \n",
    "    month = dtobj.month \n",
    "    year = dtobj.year \n",
    "    hours.append(hour) \n",
    "    day_of_weeks.append(day_of_week)\n",
    "    days.append(day) \n",
    "    months.append(month)\n",
    "    years.append(year) \n",
    "\n",
    "df['Hours'] = hours\n",
    "df['Day_of_weeks'] = day_of_weeks \n",
    "df['Days'] = days \n",
    "df['Months'] = months \n",
    "df['Years'] = years \n",
    "\n",
    "targets = [] \n",
    "close = df['close'].values\n",
    "# 0: long, 1: short, 2: hold \n",
    "threshold = 0.002\n",
    "for i in range(len(close)-1):\n",
    "    ret = (close[i+1] - close[i]) / close[i] \n",
    "    '''\n",
    "    if ret > -threshold and ret < threshold:\n",
    "        targets.append(2) \n",
    "    elif ret <= -threshold:\n",
    "        targets.append(1) \n",
    "    elif ret >= threshold: \n",
    "        targets.append(0) \n",
    "    ''' \n",
    "    if ret > 0:\n",
    "        targets.append(0) \n",
    "    elif ret <= 0:\n",
    "        targets.append(1) \n",
    "        \n",
    "targets.append(None) \n",
    "df['target'] = targets \n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day_of_weeks</th>\n",
       "      <th>Days</th>\n",
       "      <th>Months</th>\n",
       "      <th>Years</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-25 10:00:00</th>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 11:00:00</th>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>438.873</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25 12:00:00</th>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>529.318</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close   volume  Hours  \\\n",
       "datetime                                                              \n",
       "2020-03-25 10:00:00  6500.0  6591.5  6500.0  6591.5    0.004     10   \n",
       "2020-03-25 11:00:00  6591.5  6628.5  6457.5  6511.5  438.873     11   \n",
       "2020-03-25 12:00:00  6511.5  6588.5  6502.0  6583.5  529.318     12   \n",
       "\n",
       "                     Day_of_weeks  Days  Months  Years  target  \n",
       "datetime                                                        \n",
       "2020-03-25 10:00:00             2    25       3   2020     1.0  \n",
       "2020-03-25 11:00:00             2    25       3   2020     0.0  \n",
       "2020-03-25 12:00:00             2    25       3   2020     0.0  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(pd.DatetimeIndex(df['datetime']), inplace=True)\n",
    "df = df.drop(columns={'datetime'})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differencing(df, lookback=121): \n",
    "    columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    for col in columns: \n",
    "        feature_values = df[col].values  \n",
    "        d = {} \n",
    "        for i in range(1, lookback): \n",
    "            d['{}_Differenced_{}'.format(col, i)] = []\n",
    "        for i in tqdm(range(df.shape[0]), position=0, leave=True): \n",
    "            if i < lookback: \n",
    "                for j in range(1, lookback): \n",
    "                    d['{}_Differenced_{}'.format(col, j)].append(None)\n",
    "            else: \n",
    "                for j in range(1, lookback): \n",
    "                    if col == \"volume\": \n",
    "                        if feature_values[i-j] == 0:\n",
    "                            ret = 1 \n",
    "                        else:\n",
    "                            ret = feature_values[i] / feature_values[i-j] \n",
    "                    else: \n",
    "                        ret = feature_values[i] / feature_values[i-j] \n",
    "                    d['{}_Differenced_{}'.format(col, j)].append(ret) \n",
    "        for key, value in d.items():\n",
    "            df[key] = value\n",
    "    return df \n",
    "\n",
    "def upper_shadow(df):\n",
    "    return df['high']-np.maximum(df['close'], df['open']) \n",
    "\n",
    "def lower_shadow(df):\n",
    "    return np.minimum(df['close'], df['open']) - df['low'] \n",
    "\n",
    "def feature_engineering(df): \n",
    "    print(\"===== adding technical indicator features =====\")\n",
    "    df.ta.strategy('all') \n",
    "    indicators = [] \n",
    "    for col in df.columns:\n",
    "        val = df[col].values \n",
    "        nan_cnt = np.sum(np.isnan(val)) \n",
    "        if nan_cnt <= 50:\n",
    "            indicators.append(col)\n",
    "    df = df[indicators] \n",
    "    \n",
    "    print(\"===== adding additional technical indicator features =====\")\n",
    "    df['upper_shadow'] = upper_shadow(df) \n",
    "    df['lower_shadow'] = lower_shadow(df) \n",
    "    for col in ['open', 'high', 'low', 'close']:\n",
    "        df[\"Log_1p_{}\".format(col)] = np.log1p(df[col]) \n",
    "    \n",
    "    print(\"===== differencing =====\")\n",
    "    df = differencing(df)   \n",
    "    \n",
    "    print(\"===== checking if data is outlier =====\")\n",
    "    is_outlier = [None] \n",
    "    close = df['close'].values \n",
    "    for i in tqdm(range(1, close.shape[0])):\n",
    "        ret = (close[i]-close[i-1]) / close[i-1]\n",
    "        if ret >= 0.01 or ret <= -0.01:\n",
    "            is_outlier.append(1) \n",
    "        else:\n",
    "            is_outlier.append(0) \n",
    "    df['is_outlier'] = is_outlier \n",
    "    \n",
    "    df = df.dropna() \n",
    "    \n",
    "    return df, indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== adding technical indicator features =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:12, 10.50it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== adding additional technical indicator features =====\n",
      "===== differencing =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16870/16870 [00:01<00:00, 9991.89it/s] \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████| 16870/16870 [00:01<00:00, 10272.15it/s]\n",
      "100%|██████████| 16870/16870 [00:01<00:00, 11437.33it/s]\n",
      "100%|██████████| 16870/16870 [00:01<00:00, 9960.09it/s]\n",
      "100%|██████████| 16870/16870 [00:02<00:00, 6793.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== checking if data is outlier =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16869/16869 [00:00<00:00, 814346.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df, indicators = feature_engineering(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16723, 879)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Day_of_weeks</th>\n",
       "      <th>Days</th>\n",
       "      <th>Months</th>\n",
       "      <th>Years</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_Differenced_112</th>\n",
       "      <th>volume_Differenced_113</th>\n",
       "      <th>volume_Differenced_114</th>\n",
       "      <th>volume_Differenced_115</th>\n",
       "      <th>volume_Differenced_116</th>\n",
       "      <th>volume_Differenced_117</th>\n",
       "      <th>volume_Differenced_118</th>\n",
       "      <th>volume_Differenced_119</th>\n",
       "      <th>volume_Differenced_120</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-30 11:00:00</th>\n",
       "      <td>6273.0</td>\n",
       "      <td>6386.0</td>\n",
       "      <td>6266.5</td>\n",
       "      <td>6358.5</td>\n",
       "      <td>816.437</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>75.358778</td>\n",
       "      <td>47.225648</td>\n",
       "      <td>49.412153</td>\n",
       "      <td>35.214018</td>\n",
       "      <td>39.454743</td>\n",
       "      <td>3.154325</td>\n",
       "      <td>1.817689</td>\n",
       "      <td>1.542432</td>\n",
       "      <td>1.860304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 12:00:00</th>\n",
       "      <td>6358.5</td>\n",
       "      <td>6374.5</td>\n",
       "      <td>6285.0</td>\n",
       "      <td>6302.5</td>\n",
       "      <td>742.262</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>36.539431</td>\n",
       "      <td>68.512276</td>\n",
       "      <td>42.935099</td>\n",
       "      <td>44.922956</td>\n",
       "      <td>32.014751</td>\n",
       "      <td>35.870198</td>\n",
       "      <td>2.867748</td>\n",
       "      <td>1.652549</td>\n",
       "      <td>1.402299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 13:00:00</th>\n",
       "      <td>6302.5</td>\n",
       "      <td>6338.5</td>\n",
       "      <td>6297.5</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>575.246</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>63.739169</td>\n",
       "      <td>28.317712</td>\n",
       "      <td>53.096363</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>34.814864</td>\n",
       "      <td>24.811128</td>\n",
       "      <td>27.799062</td>\n",
       "      <td>2.222477</td>\n",
       "      <td>1.280709</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close   volume  Hours  \\\n",
       "datetime                                                              \n",
       "2020-03-30 11:00:00  6273.0  6386.0  6266.5  6358.5  816.437     11   \n",
       "2020-03-30 12:00:00  6358.5  6374.5  6285.0  6302.5  742.262     12   \n",
       "2020-03-30 13:00:00  6302.5  6338.5  6297.5  6302.0  575.246     13   \n",
       "\n",
       "                     Day_of_weeks  Days  Months  Years  ...  \\\n",
       "datetime                                                ...   \n",
       "2020-03-30 11:00:00             0    30       3   2020  ...   \n",
       "2020-03-30 12:00:00             0    30       3   2020  ...   \n",
       "2020-03-30 13:00:00             0    30       3   2020  ...   \n",
       "\n",
       "                     volume_Differenced_112  volume_Differenced_113  \\\n",
       "datetime                                                              \n",
       "2020-03-30 11:00:00               75.358778               47.225648   \n",
       "2020-03-30 12:00:00               36.539431               68.512276   \n",
       "2020-03-30 13:00:00               63.739169               28.317712   \n",
       "\n",
       "                     volume_Differenced_114  volume_Differenced_115  \\\n",
       "datetime                                                              \n",
       "2020-03-30 11:00:00               49.412153               35.214018   \n",
       "2020-03-30 12:00:00               42.935099               44.922956   \n",
       "2020-03-30 13:00:00               53.096363               33.274294   \n",
       "\n",
       "                     volume_Differenced_116  volume_Differenced_117  \\\n",
       "datetime                                                              \n",
       "2020-03-30 11:00:00               39.454743                3.154325   \n",
       "2020-03-30 12:00:00               32.014751               35.870198   \n",
       "2020-03-30 13:00:00               34.814864               24.811128   \n",
       "\n",
       "                     volume_Differenced_118  volume_Differenced_119  \\\n",
       "datetime                                                              \n",
       "2020-03-30 11:00:00                1.817689                1.542432   \n",
       "2020-03-30 12:00:00                2.867748                1.652549   \n",
       "2020-03-30 13:00:00               27.799062                2.222477   \n",
       "\n",
       "                     volume_Differenced_120  is_outlier  \n",
       "datetime                                                 \n",
       "2020-03-30 11:00:00                1.860304         1.0  \n",
       "2020-03-30 12:00:00                1.402299         0.0  \n",
       "2020-03-30 13:00:00                1.280709         0.0  \n",
       "\n",
       "[3 rows x 879 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13857, 879), (1540, 879), (1326, 879))"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[df['Years'] != 2022] \n",
    "test_df = df[df['Years'] == 2022] \n",
    "\n",
    "train_size = int(train_df.shape[0] * 0.9) \n",
    "val_df = train_df.iloc[train_size:, :] \n",
    "train_df = train_df.iloc[:train_size,:] \n",
    "\n",
    "train_df.shape, val_df.shape, test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = []\n",
    "for col in train_df.columns:\n",
    "    if col != 'target' and col != 'Years':\n",
    "        input_features.append(col) \n",
    "        \n",
    "X_train = train_df[input_features].values\n",
    "Y_train = train_df['target'].values \n",
    "Y_train = Y_train.reshape((-1,1))\n",
    "\n",
    "X_val = val_df[input_features].values\n",
    "Y_val = val_df['target'].values \n",
    "Y_val = Y_val.reshape((-1,1))\n",
    "\n",
    "X_test = test_df[input_features].values\n",
    "Y_test = test_df['target'].values \n",
    "Y_test = Y_test.reshape((-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 0.77429 | val_0_accuracy: 0.51039 | val_0_balanced_accuracy: 0.5013  |  0:00:01s\n",
      "epoch 1  | loss: 0.71251 | val_0_accuracy: 0.48961 | val_0_balanced_accuracy: 0.48899 |  0:00:02s\n",
      "epoch 2  | loss: 0.6966  | val_0_accuracy: 0.48312 | val_0_balanced_accuracy: 0.49933 |  0:00:03s\n",
      "epoch 3  | loss: 0.69495 | val_0_accuracy: 0.49675 | val_0_balanced_accuracy: 0.50929 |  0:00:05s\n",
      "epoch 4  | loss: 0.69414 | val_0_accuracy: 0.48571 | val_0_balanced_accuracy: 0.49648 |  0:00:06s\n",
      "epoch 5  | loss: 0.69407 | val_0_accuracy: 0.48312 | val_0_balanced_accuracy: 0.49924 |  0:00:07s\n",
      "epoch 6  | loss: 0.69374 | val_0_accuracy: 0.47403 | val_0_balanced_accuracy: 0.48571 |  0:00:08s\n",
      "epoch 7  | loss: 0.69326 | val_0_accuracy: 0.48052 | val_0_balanced_accuracy: 0.49095 |  0:00:10s\n",
      "epoch 8  | loss: 0.69273 | val_0_accuracy: 0.5013  | val_0_balanced_accuracy: 0.51061 |  0:00:11s\n",
      "epoch 9  | loss: 0.69235 | val_0_accuracy: 0.48571 | val_0_balanced_accuracy: 0.50075 |  0:00:12s\n",
      "epoch 10 | loss: 0.69263 | val_0_accuracy: 0.49935 | val_0_balanced_accuracy: 0.514   |  0:00:13s\n",
      "epoch 11 | loss: 0.69209 | val_0_accuracy: 0.52078 | val_0_balanced_accuracy: 0.52644 |  0:00:15s\n",
      "epoch 12 | loss: 0.69177 | val_0_accuracy: 0.48377 | val_0_balanced_accuracy: 0.5     |  0:00:16s\n",
      "epoch 13 | loss: 0.69172 | val_0_accuracy: 0.49091 | val_0_balanced_accuracy: 0.50574 |  0:00:17s\n",
      "epoch 14 | loss: 0.69115 | val_0_accuracy: 0.49481 | val_0_balanced_accuracy: 0.50896 |  0:00:18s\n",
      "epoch 15 | loss: 0.69098 | val_0_accuracy: 0.51429 | val_0_balanced_accuracy: 0.52238 |  0:00:20s\n",
      "epoch 16 | loss: 0.69083 | val_0_accuracy: 0.50649 | val_0_balanced_accuracy: 0.51488 |  0:00:21s\n",
      "epoch 17 | loss: 0.69096 | val_0_accuracy: 0.53766 | val_0_balanced_accuracy: 0.5395  |  0:00:22s\n",
      "epoch 18 | loss: 0.69028 | val_0_accuracy: 0.52468 | val_0_balanced_accuracy: 0.52198 |  0:00:23s\n",
      "epoch 19 | loss: 0.69017 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.52652 |  0:00:24s\n",
      "epoch 20 | loss: 0.68995 | val_0_accuracy: 0.52532 | val_0_balanced_accuracy: 0.51729 |  0:00:26s\n",
      "epoch 21 | loss: 0.68972 | val_0_accuracy: 0.52987 | val_0_balanced_accuracy: 0.51802 |  0:00:27s\n",
      "epoch 22 | loss: 0.68995 | val_0_accuracy: 0.51883 | val_0_balanced_accuracy: 0.50855 |  0:00:28s\n",
      "epoch 23 | loss: 0.68996 | val_0_accuracy: 0.52013 | val_0_balanced_accuracy: 0.515   |  0:00:29s\n",
      "epoch 24 | loss: 0.68955 | val_0_accuracy: 0.53766 | val_0_balanced_accuracy: 0.52616 |  0:00:31s\n",
      "epoch 25 | loss: 0.69043 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.52125 |  0:00:32s\n",
      "epoch 26 | loss: 0.68988 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.52429 |  0:00:33s\n",
      "epoch 27 | loss: 0.69041 | val_0_accuracy: 0.52532 | val_0_balanced_accuracy: 0.5202  |  0:00:34s\n",
      "epoch 28 | loss: 0.68982 | val_0_accuracy: 0.52792 | val_0_balanced_accuracy: 0.52056 |  0:00:36s\n",
      "epoch 29 | loss: 0.69048 | val_0_accuracy: 0.53766 | val_0_balanced_accuracy: 0.5297  |  0:00:37s\n",
      "epoch 30 | loss: 0.68991 | val_0_accuracy: 0.54026 | val_0_balanced_accuracy: 0.53513 |  0:00:38s\n",
      "epoch 31 | loss: 0.68968 | val_0_accuracy: 0.53896 | val_0_balanced_accuracy: 0.53856 |  0:00:39s\n",
      "epoch 32 | loss: 0.69047 | val_0_accuracy: 0.52468 | val_0_balanced_accuracy: 0.52135 |  0:00:41s\n",
      "epoch 33 | loss: 0.68999 | val_0_accuracy: 0.53377 | val_0_balanced_accuracy: 0.53311 |  0:00:42s\n",
      "epoch 34 | loss: 0.6906  | val_0_accuracy: 0.52792 | val_0_balanced_accuracy: 0.52782 |  0:00:43s\n",
      "epoch 35 | loss: 0.69057 | val_0_accuracy: 0.52597 | val_0_balanced_accuracy: 0.5229  |  0:00:44s\n",
      "epoch 36 | loss: 0.69032 | val_0_accuracy: 0.53571 | val_0_balanced_accuracy: 0.53622 |  0:00:45s\n",
      "epoch 37 | loss: 0.68935 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.53353 |  0:00:47s\n",
      "epoch 38 | loss: 0.68979 | val_0_accuracy: 0.54091 | val_0_balanced_accuracy: 0.54045 |  0:00:48s\n",
      "epoch 39 | loss: 0.68934 | val_0_accuracy: 0.53117 | val_0_balanced_accuracy: 0.52671 |  0:00:49s\n",
      "epoch 40 | loss: 0.6899  | val_0_accuracy: 0.53831 | val_0_balanced_accuracy: 0.54012 |  0:00:50s\n",
      "epoch 41 | loss: 0.68897 | val_0_accuracy: 0.54416 | val_0_balanced_accuracy: 0.54642 |  0:00:52s\n",
      "epoch 42 | loss: 0.68973 | val_0_accuracy: 0.53052 | val_0_balanced_accuracy: 0.53612 |  0:00:53s\n",
      "epoch 43 | loss: 0.68854 | val_0_accuracy: 0.52273 | val_0_balanced_accuracy: 0.52824 |  0:00:54s\n",
      "epoch 44 | loss: 0.68857 | val_0_accuracy: 0.5526  | val_0_balanced_accuracy: 0.55358 |  0:00:56s\n",
      "epoch 45 | loss: 0.68976 | val_0_accuracy: 0.54026 | val_0_balanced_accuracy: 0.54315 |  0:00:57s\n",
      "epoch 46 | loss: 0.68868 | val_0_accuracy: 0.54156 | val_0_balanced_accuracy: 0.545   |  0:00:58s\n",
      "epoch 47 | loss: 0.68837 | val_0_accuracy: 0.53896 | val_0_balanced_accuracy: 0.54324 |  0:00:59s\n",
      "epoch 48 | loss: 0.68813 | val_0_accuracy: 0.52338 | val_0_balanced_accuracy: 0.52937 |  0:01:00s\n",
      "epoch 49 | loss: 0.68818 | val_0_accuracy: 0.53571 | val_0_balanced_accuracy: 0.53964 |  0:01:02s\n",
      "epoch 50 | loss: 0.68763 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.53801 |  0:01:03s\n",
      "epoch 51 | loss: 0.68792 | val_0_accuracy: 0.53506 | val_0_balanced_accuracy: 0.53846 |  0:01:04s\n",
      "epoch 52 | loss: 0.68811 | val_0_accuracy: 0.53312 | val_0_balanced_accuracy: 0.53556 |  0:01:05s\n",
      "epoch 53 | loss: 0.68843 | val_0_accuracy: 0.52857 | val_0_balanced_accuracy: 0.53542 |  0:01:07s\n",
      "epoch 54 | loss: 0.68765 | val_0_accuracy: 0.54481 | val_0_balanced_accuracy: 0.54688 |  0:01:08s\n",
      "epoch 55 | loss: 0.68811 | val_0_accuracy: 0.53377 | val_0_balanced_accuracy: 0.54011 |  0:01:09s\n",
      "epoch 56 | loss: 0.68792 | val_0_accuracy: 0.54545 | val_0_balanced_accuracy: 0.54882 |  0:01:10s\n",
      "epoch 57 | loss: 0.68818 | val_0_accuracy: 0.54026 | val_0_balanced_accuracy: 0.54471 |  0:01:12s\n",
      "epoch 58 | loss: 0.68791 | val_0_accuracy: 0.53701 | val_0_balanced_accuracy: 0.54161 |  0:01:13s\n",
      "epoch 59 | loss: 0.68798 | val_0_accuracy: 0.5461  | val_0_balanced_accuracy: 0.54915 |  0:01:14s\n",
      "epoch 60 | loss: 0.68783 | val_0_accuracy: 0.53766 | val_0_balanced_accuracy: 0.54131 |  0:01:15s\n",
      "epoch 61 | loss: 0.6888  | val_0_accuracy: 0.54286 | val_0_balanced_accuracy: 0.54516 |  0:01:16s\n",
      "epoch 62 | loss: 0.68835 | val_0_accuracy: 0.53701 | val_0_balanced_accuracy: 0.54233 |  0:01:18s\n",
      "epoch 63 | loss: 0.68745 | val_0_accuracy: 0.54481 | val_0_balanced_accuracy: 0.54945 |  0:01:19s\n",
      "epoch 64 | loss: 0.68819 | val_0_accuracy: 0.54026 | val_0_balanced_accuracy: 0.54197 |  0:01:20s\n",
      "epoch 65 | loss: 0.68803 | val_0_accuracy: 0.52987 | val_0_balanced_accuracy: 0.53701 |  0:01:21s\n",
      "epoch 66 | loss: 0.68804 | val_0_accuracy: 0.53701 | val_0_balanced_accuracy: 0.54208 |  0:01:23s\n",
      "epoch 67 | loss: 0.68905 | val_0_accuracy: 0.54156 | val_0_balanced_accuracy: 0.54403 |  0:01:24s\n",
      "epoch 68 | loss: 0.68884 | val_0_accuracy: 0.52532 | val_0_balanced_accuracy: 0.53046 |  0:01:25s\n",
      "epoch 69 | loss: 0.68867 | val_0_accuracy: 0.54351 | val_0_balanced_accuracy: 0.54668 |  0:01:26s\n",
      "epoch 70 | loss: 0.68781 | val_0_accuracy: 0.52987 | val_0_balanced_accuracy: 0.53478 |  0:01:27s\n",
      "epoch 71 | loss: 0.68734 | val_0_accuracy: 0.53182 | val_0_balanced_accuracy: 0.53607 |  0:01:29s\n",
      "epoch 72 | loss: 0.68647 | val_0_accuracy: 0.53442 | val_0_balanced_accuracy: 0.53834 |  0:01:30s\n",
      "epoch 73 | loss: 0.68707 | val_0_accuracy: 0.54156 | val_0_balanced_accuracy: 0.54622 |  0:01:31s\n",
      "epoch 74 | loss: 0.68695 | val_0_accuracy: 0.54286 | val_0_balanced_accuracy: 0.54769 |  0:01:32s\n",
      "epoch 75 | loss: 0.68726 | val_0_accuracy: 0.53117 | val_0_balanced_accuracy: 0.53591 |  0:01:33s\n",
      "epoch 76 | loss: 0.68569 | val_0_accuracy: 0.52727 | val_0_balanced_accuracy: 0.53522 |  0:01:35s\n",
      "epoch 77 | loss: 0.68401 | val_0_accuracy: 0.52078 | val_0_balanced_accuracy: 0.53002 |  0:01:36s\n",
      "epoch 78 | loss: 0.6823  | val_0_accuracy: 0.54805 | val_0_balanced_accuracy: 0.55631 |  0:01:37s\n",
      "epoch 79 | loss: 0.67696 | val_0_accuracy: 0.56494 | val_0_balanced_accuracy: 0.57275 |  0:01:38s\n",
      "epoch 80 | loss: 0.67497 | val_0_accuracy: 0.60195 | val_0_balanced_accuracy: 0.60704 |  0:01:40s\n",
      "epoch 81 | loss: 0.67024 | val_0_accuracy: 0.59805 | val_0_balanced_accuracy: 0.6028  |  0:01:41s\n",
      "epoch 82 | loss: 0.66256 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61793 |  0:01:42s\n",
      "epoch 83 | loss: 0.6591  | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62967 |  0:01:43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84 | loss: 0.65286 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64434 |  0:01:44s\n",
      "epoch 85 | loss: 0.64974 | val_0_accuracy: 0.65    | val_0_balanced_accuracy: 0.64898 |  0:01:46s\n",
      "epoch 86 | loss: 0.64574 | val_0_accuracy: 0.64091 | val_0_balanced_accuracy: 0.64009 |  0:01:47s\n",
      "epoch 87 | loss: 0.64313 | val_0_accuracy: 0.6487  | val_0_balanced_accuracy: 0.6492  |  0:01:48s\n",
      "epoch 88 | loss: 0.63558 | val_0_accuracy: 0.64545 | val_0_balanced_accuracy: 0.64305 |  0:01:49s\n",
      "epoch 89 | loss: 0.63391 | val_0_accuracy: 0.65974 | val_0_balanced_accuracy: 0.66014 |  0:01:51s\n",
      "epoch 90 | loss: 0.6362  | val_0_accuracy: 0.65714 | val_0_balanced_accuracy: 0.65636 |  0:01:52s\n",
      "epoch 91 | loss: 0.63391 | val_0_accuracy: 0.65649 | val_0_balanced_accuracy: 0.6559  |  0:01:53s\n",
      "epoch 92 | loss: 0.62759 | val_0_accuracy: 0.65584 | val_0_balanced_accuracy: 0.65607 |  0:01:54s\n",
      "epoch 93 | loss: 0.6273  | val_0_accuracy: 0.64416 | val_0_balanced_accuracy: 0.64479 |  0:01:55s\n",
      "epoch 94 | loss: 0.62948 | val_0_accuracy: 0.6539  | val_0_balanced_accuracy: 0.65275 |  0:01:57s\n",
      "epoch 95 | loss: 0.62865 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64156 |  0:01:58s\n",
      "epoch 96 | loss: 0.62942 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63649 |  0:01:59s\n",
      "epoch 97 | loss: 0.62789 | val_0_accuracy: 0.65    | val_0_balanced_accuracy: 0.64885 |  0:02:00s\n",
      "epoch 98 | loss: 0.61902 | val_0_accuracy: 0.6513  | val_0_balanced_accuracy: 0.64736 |  0:02:01s\n",
      "epoch 99 | loss: 0.63408 | val_0_accuracy: 0.65    | val_0_balanced_accuracy: 0.64632 |  0:02:02s\n",
      "epoch 100| loss: 0.64375 | val_0_accuracy: 0.65779 | val_0_balanced_accuracy: 0.655   |  0:02:04s\n",
      "epoch 101| loss: 0.63541 | val_0_accuracy: 0.66364 | val_0_balanced_accuracy: 0.66231 |  0:02:05s\n",
      "epoch 102| loss: 0.631   | val_0_accuracy: 0.66104 | val_0_balanced_accuracy: 0.65979 |  0:02:06s\n",
      "epoch 103| loss: 0.62541 | val_0_accuracy: 0.65195 | val_0_balanced_accuracy: 0.65361 |  0:02:07s\n",
      "epoch 104| loss: 0.6236  | val_0_accuracy: 0.66494 | val_0_balanced_accuracy: 0.66454 |  0:02:08s\n",
      "epoch 105| loss: 0.62083 | val_0_accuracy: 0.66234 | val_0_balanced_accuracy: 0.66122 |  0:02:10s\n",
      "epoch 106| loss: 0.61708 | val_0_accuracy: 0.65649 | val_0_balanced_accuracy: 0.65472 |  0:02:11s\n",
      "epoch 107| loss: 0.61532 | val_0_accuracy: 0.66623 | val_0_balanced_accuracy: 0.66559 |  0:02:12s\n",
      "epoch 108| loss: 0.61629 | val_0_accuracy: 0.65974 | val_0_balanced_accuracy: 0.65909 |  0:02:13s\n",
      "epoch 109| loss: 0.6122  | val_0_accuracy: 0.66039 | val_0_balanced_accuracy: 0.65748 |  0:02:14s\n",
      "epoch 110| loss: 0.61322 | val_0_accuracy: 0.64935 | val_0_balanced_accuracy: 0.64548 |  0:02:16s\n",
      "epoch 111| loss: 0.62508 | val_0_accuracy: 0.66558 | val_0_balanced_accuracy: 0.665   |  0:02:17s\n",
      "epoch 112| loss: 0.61831 | val_0_accuracy: 0.65714 | val_0_balanced_accuracy: 0.65484 |  0:02:18s\n",
      "epoch 113| loss: 0.61804 | val_0_accuracy: 0.66299 | val_0_balanced_accuracy: 0.65978 |  0:02:19s\n",
      "epoch 114| loss: 0.61407 | val_0_accuracy: 0.65649 | val_0_balanced_accuracy: 0.65535 |  0:02:21s\n",
      "epoch 115| loss: 0.61386 | val_0_accuracy: 0.63961 | val_0_balanced_accuracy: 0.63495 |  0:02:22s\n",
      "epoch 116| loss: 0.61207 | val_0_accuracy: 0.66169 | val_0_balanced_accuracy: 0.66    |  0:02:23s\n",
      "epoch 117| loss: 0.60998 | val_0_accuracy: 0.65065 | val_0_balanced_accuracy: 0.64999 |  0:02:24s\n",
      "epoch 118| loss: 0.60808 | val_0_accuracy: 0.65065 | val_0_balanced_accuracy: 0.65053 |  0:02:26s\n",
      "epoch 119| loss: 0.60373 | val_0_accuracy: 0.64805 | val_0_balanced_accuracy: 0.64852 |  0:02:27s\n",
      "epoch 120| loss: 0.60421 | val_0_accuracy: 0.64416 | val_0_balanced_accuracy: 0.64078 |  0:02:28s\n",
      "epoch 121| loss: 0.6055  | val_0_accuracy: 0.63766 | val_0_balanced_accuracy: 0.63513 |  0:02:29s\n",
      "epoch 122| loss: 0.60547 | val_0_accuracy: 0.64416 | val_0_balanced_accuracy: 0.64264 |  0:02:31s\n",
      "epoch 123| loss: 0.60483 | val_0_accuracy: 0.64935 | val_0_balanced_accuracy: 0.64721 |  0:02:32s\n",
      "epoch 124| loss: 0.6018  | val_0_accuracy: 0.64675 | val_0_balanced_accuracy: 0.64537 |  0:02:33s\n",
      "epoch 125| loss: 0.60308 | val_0_accuracy: 0.6539  | val_0_balanced_accuracy: 0.65292 |  0:02:34s\n",
      "epoch 126| loss: 0.60732 | val_0_accuracy: 0.64481 | val_0_balanced_accuracy: 0.64665 |  0:02:36s\n",
      "epoch 127| loss: 0.60812 | val_0_accuracy: 0.65584 | val_0_balanced_accuracy: 0.65637 |  0:02:37s\n",
      "epoch 128| loss: 0.60262 | val_0_accuracy: 0.6513  | val_0_balanced_accuracy: 0.6504  |  0:02:38s\n",
      "epoch 129| loss: 0.59823 | val_0_accuracy: 0.65519 | val_0_balanced_accuracy: 0.65435 |  0:02:39s\n",
      "epoch 130| loss: 0.60162 | val_0_accuracy: 0.65519 | val_0_balanced_accuracy: 0.65519 |  0:02:41s\n",
      "epoch 131| loss: 0.60134 | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.63896 |  0:02:42s\n",
      "epoch 132| loss: 0.6003  | val_0_accuracy: 0.64675 | val_0_balanced_accuracy: 0.64714 |  0:02:43s\n",
      "epoch 133| loss: 0.6063  | val_0_accuracy: 0.65779 | val_0_balanced_accuracy: 0.65758 |  0:02:44s\n",
      "epoch 134| loss: 0.59937 | val_0_accuracy: 0.63571 | val_0_balanced_accuracy: 0.63712 |  0:02:45s\n",
      "epoch 135| loss: 0.61644 | val_0_accuracy: 0.65325 | val_0_balanced_accuracy: 0.65288 |  0:02:47s\n",
      "epoch 136| loss: 0.61194 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64278 |  0:02:48s\n",
      "epoch 137| loss: 0.6087  | val_0_accuracy: 0.66104 | val_0_balanced_accuracy: 0.65946 |  0:02:49s\n",
      "epoch 138| loss: 0.59989 | val_0_accuracy: 0.6461  | val_0_balanced_accuracy: 0.64575 |  0:02:51s\n",
      "epoch 139| loss: 0.60309 | val_0_accuracy: 0.65195 | val_0_balanced_accuracy: 0.65061 |  0:02:52s\n",
      "epoch 140| loss: 0.60434 | val_0_accuracy: 0.64545 | val_0_balanced_accuracy: 0.64571 |  0:02:53s\n",
      "epoch 141| loss: 0.59798 | val_0_accuracy: 0.65519 | val_0_balanced_accuracy: 0.65451 |  0:02:54s\n",
      "epoch 142| loss: 0.59293 | val_0_accuracy: 0.65844 | val_0_balanced_accuracy: 0.65669 |  0:02:56s\n",
      "epoch 143| loss: 0.59129 | val_0_accuracy: 0.64935 | val_0_balanced_accuracy: 0.64822 |  0:02:57s\n",
      "epoch 144| loss: 0.58536 | val_0_accuracy: 0.64675 | val_0_balanced_accuracy: 0.64722 |  0:02:58s\n",
      "epoch 145| loss: 0.58611 | val_0_accuracy: 0.6526  | val_0_balanced_accuracy: 0.65179 |  0:02:59s\n",
      "epoch 146| loss: 0.58349 | val_0_accuracy: 0.6526  | val_0_balanced_accuracy: 0.65305 |  0:03:00s\n",
      "epoch 147| loss: 0.58318 | val_0_accuracy: 0.6526  | val_0_balanced_accuracy: 0.65322 |  0:03:02s\n",
      "epoch 148| loss: 0.5858  | val_0_accuracy: 0.64091 | val_0_balanced_accuracy: 0.64144 |  0:03:03s\n",
      "epoch 149| loss: 0.58495 | val_0_accuracy: 0.63377 | val_0_balanced_accuracy: 0.6341  |  0:03:04s\n",
      "epoch 150| loss: 0.58921 | val_0_accuracy: 0.6539  | val_0_balanced_accuracy: 0.65376 |  0:03:05s\n",
      "epoch 151| loss: 0.58236 | val_0_accuracy: 0.65195 | val_0_balanced_accuracy: 0.65141 |  0:03:06s\n",
      "epoch 152| loss: 0.57905 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63692 |  0:03:08s\n",
      "epoch 153| loss: 0.57457 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.63004 |  0:03:09s\n",
      "epoch 154| loss: 0.57159 | val_0_accuracy: 0.64156 | val_0_balanced_accuracy: 0.64186 |  0:03:10s\n",
      "epoch 155| loss: 0.5724  | val_0_accuracy: 0.64935 | val_0_balanced_accuracy: 0.6494  |  0:03:11s\n",
      "epoch 156| loss: 0.57215 | val_0_accuracy: 0.6513  | val_0_balanced_accuracy: 0.6507  |  0:03:13s\n",
      "epoch 157| loss: 0.57013 | val_0_accuracy: 0.6474  | val_0_balanced_accuracy: 0.64904 |  0:03:14s\n",
      "epoch 158| loss: 0.56805 | val_0_accuracy: 0.65    | val_0_balanced_accuracy: 0.65104 |  0:03:15s\n",
      "epoch 159| loss: 0.57097 | val_0_accuracy: 0.6474  | val_0_balanced_accuracy: 0.64752 |  0:03:16s\n",
      "epoch 160| loss: 0.56946 | val_0_accuracy: 0.6474  | val_0_balanced_accuracy: 0.64747 |  0:03:18s\n",
      "epoch 161| loss: 0.56122 | val_0_accuracy: 0.64026 | val_0_balanced_accuracy: 0.64224 |  0:03:19s\n",
      "epoch 162| loss: 0.5682  | val_0_accuracy: 0.6474  | val_0_balanced_accuracy: 0.65034 |  0:03:20s\n",
      "epoch 163| loss: 0.56055 | val_0_accuracy: 0.64545 | val_0_balanced_accuracy: 0.64694 |  0:03:21s\n",
      "epoch 164| loss: 0.56182 | val_0_accuracy: 0.66104 | val_0_balanced_accuracy: 0.66195 |  0:03:22s\n",
      "epoch 165| loss: 0.56148 | val_0_accuracy: 0.65909 | val_0_balanced_accuracy: 0.65833 |  0:03:24s\n",
      "epoch 166| loss: 0.56159 | val_0_accuracy: 0.64481 | val_0_balanced_accuracy: 0.64559 |  0:03:25s\n",
      "epoch 167| loss: 0.55664 | val_0_accuracy: 0.63701 | val_0_balanced_accuracy: 0.6383  |  0:03:26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168| loss: 0.55644 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63208 |  0:03:27s\n",
      "epoch 169| loss: 0.55602 | val_0_accuracy: 0.64026 | val_0_balanced_accuracy: 0.64317 |  0:03:29s\n",
      "epoch 170| loss: 0.5614  | val_0_accuracy: 0.6513  | val_0_balanced_accuracy: 0.65087 |  0:03:30s\n",
      "epoch 171| loss: 0.55439 | val_0_accuracy: 0.64805 | val_0_balanced_accuracy: 0.64924 |  0:03:31s\n",
      "epoch 172| loss: 0.55288 | val_0_accuracy: 0.63701 | val_0_balanced_accuracy: 0.63914 |  0:03:32s\n",
      "epoch 173| loss: 0.54265 | val_0_accuracy: 0.6461  | val_0_balanced_accuracy: 0.64571 |  0:03:33s\n",
      "epoch 174| loss: 0.54466 | val_0_accuracy: 0.64351 | val_0_balanced_accuracy: 0.64408 |  0:03:35s\n",
      "epoch 175| loss: 0.53755 | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.63934 |  0:03:36s\n",
      "epoch 176| loss: 0.54307 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.6284  |  0:03:37s\n",
      "epoch 177| loss: 0.54158 | val_0_accuracy: 0.64286 | val_0_balanced_accuracy: 0.64404 |  0:03:38s\n",
      "epoch 178| loss: 0.53878 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.62932 |  0:03:40s\n",
      "epoch 179| loss: 0.53725 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64299 |  0:03:41s\n",
      "epoch 180| loss: 0.5337  | val_0_accuracy: 0.64351 | val_0_balanced_accuracy: 0.644   |  0:03:42s\n",
      "epoch 181| loss: 0.53173 | val_0_accuracy: 0.64026 | val_0_balanced_accuracy: 0.64119 |  0:03:43s\n",
      "epoch 182| loss: 0.52698 | val_0_accuracy: 0.63182 | val_0_balanced_accuracy: 0.63441 |  0:03:45s\n",
      "epoch 183| loss: 0.53335 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63662 |  0:03:46s\n",
      "epoch 184| loss: 0.52638 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62475 |  0:03:47s\n",
      "epoch 185| loss: 0.52195 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62656 |  0:03:48s\n",
      "epoch 186| loss: 0.51831 | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63151 |  0:03:50s\n",
      "epoch 187| loss: 0.51785 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62794 |  0:03:51s\n",
      "epoch 188| loss: 0.51575 | val_0_accuracy: 0.63701 | val_0_balanced_accuracy: 0.6375  |  0:03:52s\n",
      "epoch 189| loss: 0.5147  | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.63038 |  0:03:53s\n",
      "epoch 190| loss: 0.51406 | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62345 |  0:03:55s\n",
      "epoch 191| loss: 0.51749 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62404 |  0:03:56s\n",
      "epoch 192| loss: 0.50989 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.63051 |  0:03:57s\n",
      "epoch 193| loss: 0.49961 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62513 |  0:03:58s\n",
      "epoch 194| loss: 0.51347 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.63206 |  0:03:59s\n",
      "epoch 195| loss: 0.50424 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62719 |  0:04:01s\n",
      "epoch 196| loss: 0.49783 | val_0_accuracy: 0.63182 | val_0_balanced_accuracy: 0.63424 |  0:04:02s\n",
      "epoch 197| loss: 0.49953 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62831 |  0:04:03s\n",
      "epoch 198| loss: 0.49264 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62945 |  0:04:04s\n",
      "epoch 199| loss: 0.49746 | val_0_accuracy: 0.63442 | val_0_balanced_accuracy: 0.6357  |  0:04:06s\n",
      "epoch 200| loss: 0.49432 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61701 |  0:04:07s\n",
      "epoch 201| loss: 0.50385 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63254 |  0:04:08s\n",
      "epoch 202| loss: 0.49451 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.63102 |  0:04:09s\n",
      "epoch 203| loss: 0.49656 | val_0_accuracy: 0.64286 | val_0_balanced_accuracy: 0.64235 |  0:04:10s\n",
      "epoch 204| loss: 0.48868 | val_0_accuracy: 0.63117 | val_0_balanced_accuracy: 0.63264 |  0:04:12s\n",
      "epoch 205| loss: 0.49611 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62161 |  0:04:13s\n",
      "epoch 206| loss: 0.4918  | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61758 |  0:04:14s\n",
      "epoch 207| loss: 0.48455 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62312 |  0:04:15s\n",
      "epoch 208| loss: 0.47825 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62703 |  0:04:17s\n",
      "epoch 209| loss: 0.47635 | val_0_accuracy: 0.61753 | val_0_balanced_accuracy: 0.62108 |  0:04:18s\n",
      "epoch 210| loss: 0.48031 | val_0_accuracy: 0.62922 | val_0_balanced_accuracy: 0.6283  |  0:04:19s\n",
      "epoch 211| loss: 0.47204 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62517 |  0:04:20s\n",
      "epoch 212| loss: 0.47568 | val_0_accuracy: 0.63636 | val_0_balanced_accuracy: 0.63893 |  0:04:22s\n",
      "epoch 213| loss: 0.47849 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62018 |  0:04:23s\n",
      "epoch 214| loss: 0.47692 | val_0_accuracy: 0.63442 | val_0_balanced_accuracy: 0.63671 |  0:04:24s\n",
      "epoch 215| loss: 0.47143 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62613 |  0:04:25s\n",
      "epoch 216| loss: 0.47028 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.61715 |  0:04:27s\n",
      "epoch 217| loss: 0.48207 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62202 |  0:04:28s\n",
      "epoch 218| loss: 0.49437 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63218 |  0:04:29s\n",
      "epoch 219| loss: 0.48362 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.63063 |  0:04:30s\n",
      "epoch 220| loss: 0.46704 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64341 |  0:04:32s\n",
      "epoch 221| loss: 0.45981 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.62882 |  0:04:33s\n",
      "epoch 222| loss: 0.45136 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62382 |  0:04:34s\n",
      "epoch 223| loss: 0.45837 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.62245 |  0:04:35s\n",
      "epoch 224| loss: 0.46181 | val_0_accuracy: 0.63701 | val_0_balanced_accuracy: 0.63619 |  0:04:37s\n",
      "epoch 225| loss: 0.48742 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.61012 |  0:04:38s\n",
      "epoch 226| loss: 0.48036 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62534 |  0:04:39s\n",
      "epoch 227| loss: 0.46589 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62806 |  0:04:40s\n",
      "epoch 228| loss: 0.4613  | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.63008 |  0:04:42s\n",
      "epoch 229| loss: 0.45686 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62818 |  0:04:43s\n",
      "epoch 230| loss: 0.46787 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63595 |  0:04:44s\n",
      "epoch 231| loss: 0.4843  | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61805 |  0:04:45s\n",
      "epoch 232| loss: 0.47563 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62554 |  0:04:46s\n",
      "epoch 233| loss: 0.47333 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63356 |  0:04:48s\n",
      "epoch 234| loss: 0.47748 | val_0_accuracy: 0.63312 | val_0_balanced_accuracy: 0.63609 |  0:04:49s\n",
      "epoch 235| loss: 0.45904 | val_0_accuracy: 0.62922 | val_0_balanced_accuracy: 0.62944 |  0:04:50s\n",
      "epoch 236| loss: 0.45205 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62567 |  0:04:51s\n",
      "epoch 237| loss: 0.44299 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62728 |  0:04:53s\n",
      "epoch 238| loss: 0.44758 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.62292 |  0:04:54s\n",
      "epoch 239| loss: 0.43821 | val_0_accuracy: 0.61883 | val_0_balanced_accuracy: 0.62157 |  0:04:55s\n",
      "epoch 240| loss: 0.43863 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62711 |  0:04:56s\n",
      "epoch 241| loss: 0.43673 | val_0_accuracy: 0.63766 | val_0_balanced_accuracy: 0.6385  |  0:04:57s\n",
      "epoch 242| loss: 0.43269 | val_0_accuracy: 0.63636 | val_0_balanced_accuracy: 0.63763 |  0:04:59s\n",
      "epoch 243| loss: 0.42954 | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.6398  |  0:05:00s\n",
      "epoch 244| loss: 0.43632 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62744 |  0:05:01s\n",
      "epoch 245| loss: 0.43829 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62475 |  0:05:02s\n",
      "epoch 246| loss: 0.43333 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.62739 |  0:05:03s\n",
      "epoch 247| loss: 0.43311 | val_0_accuracy: 0.61299 | val_0_balanced_accuracy: 0.61528 |  0:05:05s\n",
      "epoch 248| loss: 0.43222 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63305 |  0:05:06s\n",
      "epoch 249| loss: 0.43824 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63256 |  0:05:07s\n",
      "epoch 250| loss: 0.4419  | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.61964 |  0:05:08s\n",
      "epoch 251| loss: 0.42076 | val_0_accuracy: 0.64091 | val_0_balanced_accuracy: 0.64152 |  0:05:10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 252| loss: 0.41827 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.6105  |  0:05:11s\n",
      "epoch 253| loss: 0.41048 | val_0_accuracy: 0.59221 | val_0_balanced_accuracy: 0.59368 |  0:05:12s\n",
      "epoch 254| loss: 0.44247 | val_0_accuracy: 0.63636 | val_0_balanced_accuracy: 0.63636 |  0:05:13s\n",
      "epoch 255| loss: 0.42718 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62799 |  0:05:14s\n",
      "epoch 256| loss: 0.41744 | val_0_accuracy: 0.61299 | val_0_balanced_accuracy: 0.61566 |  0:05:16s\n",
      "epoch 257| loss: 0.41692 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.62684 |  0:05:17s\n",
      "epoch 258| loss: 0.41098 | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62295 |  0:05:18s\n",
      "epoch 259| loss: 0.47647 | val_0_accuracy: 0.62078 | val_0_balanced_accuracy: 0.62169 |  0:05:19s\n",
      "epoch 260| loss: 0.45379 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62995 |  0:05:20s\n",
      "epoch 261| loss: 0.42103 | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63003 |  0:05:22s\n",
      "epoch 262| loss: 0.43545 | val_0_accuracy: 0.64351 | val_0_balanced_accuracy: 0.64492 |  0:05:23s\n",
      "epoch 263| loss: 0.43121 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.6276  |  0:05:24s\n",
      "epoch 264| loss: 0.45662 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.6121  |  0:05:25s\n",
      "epoch 265| loss: 0.45033 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63489 |  0:05:27s\n",
      "epoch 266| loss: 0.43725 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62325 |  0:05:28s\n",
      "epoch 267| loss: 0.42168 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63163 |  0:05:29s\n",
      "epoch 268| loss: 0.41666 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62501 |  0:05:30s\n",
      "epoch 269| loss: 0.40669 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63616 |  0:05:31s\n",
      "epoch 270| loss: 0.4142  | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62807 |  0:05:32s\n",
      "epoch 271| loss: 0.40968 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.62035 |  0:05:34s\n",
      "epoch 272| loss: 0.40386 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.6175  |  0:05:35s\n",
      "epoch 273| loss: 0.40437 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62597 |  0:05:36s\n",
      "epoch 274| loss: 0.39943 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.62165 |  0:05:37s\n",
      "epoch 275| loss: 0.40325 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62113 |  0:05:38s\n",
      "epoch 276| loss: 0.39021 | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63193 |  0:05:40s\n",
      "epoch 277| loss: 0.394   | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63108 |  0:05:41s\n",
      "epoch 278| loss: 0.3866  | val_0_accuracy: 0.63312 | val_0_balanced_accuracy: 0.63322 |  0:05:42s\n",
      "epoch 279| loss: 0.38591 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61683 |  0:05:43s\n",
      "epoch 280| loss: 0.38831 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.6313  |  0:05:45s\n",
      "epoch 281| loss: 0.38722 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62555 |  0:05:46s\n",
      "epoch 282| loss: 0.41009 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62589 |  0:05:47s\n",
      "epoch 283| loss: 0.4071  | val_0_accuracy: 0.61169 | val_0_balanced_accuracy: 0.6133  |  0:05:48s\n",
      "epoch 284| loss: 0.39908 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62647 |  0:05:49s\n",
      "epoch 285| loss: 0.39453 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.6292  |  0:05:51s\n",
      "epoch 286| loss: 0.42233 | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61796 |  0:05:52s\n",
      "epoch 287| loss: 0.41332 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.61867 |  0:05:53s\n",
      "epoch 288| loss: 0.40896 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62106 |  0:05:54s\n",
      "epoch 289| loss: 0.39328 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.6214  |  0:05:56s\n",
      "epoch 290| loss: 0.38934 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61691 |  0:05:57s\n",
      "epoch 291| loss: 0.38057 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.6258  |  0:05:58s\n",
      "epoch 292| loss: 0.37069 | val_0_accuracy: 0.61753 | val_0_balanced_accuracy: 0.61943 |  0:05:59s\n",
      "epoch 293| loss: 0.36798 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62416 |  0:06:01s\n",
      "epoch 294| loss: 0.38431 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.61239 |  0:06:02s\n",
      "epoch 295| loss: 0.38288 | val_0_accuracy: 0.62078 | val_0_balanced_accuracy: 0.62215 |  0:06:03s\n",
      "epoch 296| loss: 0.37402 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.61141 |  0:06:04s\n",
      "epoch 297| loss: 0.42206 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62911 |  0:06:05s\n",
      "epoch 298| loss: 0.40548 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62579 |  0:06:07s\n",
      "epoch 299| loss: 0.3836  | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.62705 |  0:06:08s\n",
      "epoch 300| loss: 0.45833 | val_0_accuracy: 0.62338 | val_0_balanced_accuracy: 0.62627 |  0:06:09s\n",
      "epoch 301| loss: 0.47296 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63322 |  0:06:10s\n",
      "epoch 302| loss: 0.45315 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.6286  |  0:06:11s\n",
      "epoch 303| loss: 0.43066 | val_0_accuracy: 0.63312 | val_0_balanced_accuracy: 0.63381 |  0:06:13s\n",
      "epoch 304| loss: 0.40923 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62379 |  0:06:14s\n",
      "epoch 305| loss: 0.39434 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62782 |  0:06:15s\n",
      "epoch 306| loss: 0.39687 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63201 |  0:06:16s\n",
      "epoch 307| loss: 0.39351 | val_0_accuracy: 0.62922 | val_0_balanced_accuracy: 0.6294  |  0:06:18s\n",
      "epoch 308| loss: 0.3819  | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62748 |  0:06:19s\n",
      "epoch 309| loss: 0.37654 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63121 |  0:06:20s\n",
      "epoch 310| loss: 0.37723 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.6323  |  0:06:21s\n",
      "epoch 311| loss: 0.36721 | val_0_accuracy: 0.63312 | val_0_balanced_accuracy: 0.63444 |  0:06:23s\n",
      "epoch 312| loss: 0.37341 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.62764 |  0:06:24s\n",
      "epoch 313| loss: 0.36681 | val_0_accuracy: 0.63442 | val_0_balanced_accuracy: 0.63536 |  0:06:25s\n",
      "epoch 314| loss: 0.37376 | val_0_accuracy: 0.63571 | val_0_balanced_accuracy: 0.63691 |  0:06:26s\n",
      "epoch 315| loss: 0.37127 | val_0_accuracy: 0.63442 | val_0_balanced_accuracy: 0.63599 |  0:06:28s\n",
      "epoch 316| loss: 0.35576 | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63125 |  0:06:29s\n",
      "epoch 317| loss: 0.37525 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62698 |  0:06:30s\n",
      "epoch 318| loss: 0.37482 | val_0_accuracy: 0.63831 | val_0_balanced_accuracy: 0.63918 |  0:06:31s\n",
      "epoch 319| loss: 0.36178 | val_0_accuracy: 0.63571 | val_0_balanced_accuracy: 0.63662 |  0:06:32s\n",
      "epoch 320| loss: 0.36153 | val_0_accuracy: 0.64026 | val_0_balanced_accuracy: 0.64148 |  0:06:34s\n",
      "epoch 321| loss: 0.34529 | val_0_accuracy: 0.63766 | val_0_balanced_accuracy: 0.6396  |  0:06:35s\n",
      "epoch 322| loss: 0.35233 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63192 |  0:06:36s\n",
      "epoch 323| loss: 0.34839 | val_0_accuracy: 0.64805 | val_0_balanced_accuracy: 0.64844 |  0:06:37s\n",
      "epoch 324| loss: 0.3456  | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.64023 |  0:06:39s\n",
      "epoch 325| loss: 0.34622 | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62366 |  0:06:40s\n",
      "epoch 326| loss: 0.35171 | val_0_accuracy: 0.63961 | val_0_balanced_accuracy: 0.64005 |  0:06:41s\n",
      "epoch 327| loss: 0.35294 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62903 |  0:06:42s\n",
      "epoch 328| loss: 0.35369 | val_0_accuracy: 0.64221 | val_0_balanced_accuracy: 0.64291 |  0:06:43s\n",
      "epoch 329| loss: 0.3527  | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62891 |  0:06:44s\n",
      "epoch 330| loss: 0.34131 | val_0_accuracy: 0.63377 | val_0_balanced_accuracy: 0.63524 |  0:06:46s\n",
      "epoch 331| loss: 0.34028 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63649 |  0:06:47s\n",
      "epoch 332| loss: 0.35194 | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.63934 |  0:06:48s\n",
      "epoch 333| loss: 0.34859 | val_0_accuracy: 0.64091 | val_0_balanced_accuracy: 0.6408  |  0:06:49s\n",
      "epoch 334| loss: 0.34873 | val_0_accuracy: 0.63831 | val_0_balanced_accuracy: 0.63993 |  0:06:50s\n",
      "epoch 335| loss: 0.34026 | val_0_accuracy: 0.62987 | val_0_balanced_accuracy: 0.63121 |  0:06:52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 336| loss: 0.33948 | val_0_accuracy: 0.62922 | val_0_balanced_accuracy: 0.63193 |  0:06:53s\n",
      "epoch 337| loss: 0.34606 | val_0_accuracy: 0.63571 | val_0_balanced_accuracy: 0.63522 |  0:06:54s\n",
      "epoch 338| loss: 0.33355 | val_0_accuracy: 0.63182 | val_0_balanced_accuracy: 0.63255 |  0:06:55s\n",
      "epoch 339| loss: 0.33253 | val_0_accuracy: 0.64286 | val_0_balanced_accuracy: 0.64345 |  0:06:57s\n",
      "epoch 340| loss: 0.34535 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62227 |  0:06:58s\n",
      "epoch 341| loss: 0.34131 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62568 |  0:06:59s\n",
      "epoch 342| loss: 0.33951 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62865 |  0:07:00s\n",
      "epoch 343| loss: 0.33569 | val_0_accuracy: 0.62662 | val_0_balanced_accuracy: 0.62798 |  0:07:01s\n",
      "epoch 344| loss: 0.33273 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62119 |  0:07:03s\n",
      "epoch 345| loss: 0.34211 | val_0_accuracy: 0.63312 | val_0_balanced_accuracy: 0.63347 |  0:07:04s\n",
      "epoch 346| loss: 0.33278 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.62979 |  0:07:05s\n",
      "epoch 347| loss: 0.32871 | val_0_accuracy: 0.61299 | val_0_balanced_accuracy: 0.61414 |  0:07:06s\n",
      "epoch 348| loss: 0.3348  | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61918 |  0:07:07s\n",
      "epoch 349| loss: 0.34222 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.62806 |  0:07:09s\n",
      "epoch 350| loss: 0.33969 | val_0_accuracy: 0.63377 | val_0_balanced_accuracy: 0.63334 |  0:07:10s\n",
      "epoch 351| loss: 0.33234 | val_0_accuracy: 0.63247 | val_0_balanced_accuracy: 0.63276 |  0:07:11s\n",
      "epoch 352| loss: 0.32701 | val_0_accuracy: 0.60584 | val_0_balanced_accuracy: 0.60638 |  0:07:12s\n",
      "epoch 353| loss: 0.32889 | val_0_accuracy: 0.61883 | val_0_balanced_accuracy: 0.61887 |  0:07:13s\n",
      "epoch 354| loss: 0.32949 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62756 |  0:07:14s\n",
      "epoch 355| loss: 0.33577 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62805 |  0:07:16s\n",
      "epoch 356| loss: 0.3207  | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.61191 |  0:07:17s\n",
      "epoch 357| loss: 0.33421 | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.61195 |  0:07:18s\n",
      "epoch 358| loss: 0.33324 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62676 |  0:07:19s\n",
      "epoch 359| loss: 0.32383 | val_0_accuracy: 0.63117 | val_0_balanced_accuracy: 0.63019 |  0:07:20s\n",
      "epoch 360| loss: 0.32955 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62307 |  0:07:21s\n",
      "epoch 361| loss: 0.31743 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.61007 |  0:07:23s\n",
      "epoch 362| loss: 0.31578 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62252 |  0:07:24s\n",
      "epoch 363| loss: 0.32495 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61523 |  0:07:25s\n",
      "epoch 364| loss: 0.33419 | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.61279 |  0:07:26s\n",
      "epoch 365| loss: 0.33244 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60805 |  0:07:28s\n",
      "epoch 366| loss: 0.31706 | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.61136 |  0:07:29s\n",
      "epoch 367| loss: 0.32265 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62287 |  0:07:30s\n",
      "epoch 368| loss: 0.32802 | val_0_accuracy: 0.62078 | val_0_balanced_accuracy: 0.62063 |  0:07:31s\n",
      "epoch 369| loss: 0.33136 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.62038 |  0:07:32s\n",
      "epoch 370| loss: 0.33135 | val_0_accuracy: 0.61429 | val_0_balanced_accuracy: 0.6154  |  0:07:34s\n",
      "epoch 371| loss: 0.31177 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.61996 |  0:07:35s\n",
      "epoch 372| loss: 0.32077 | val_0_accuracy: 0.63377 | val_0_balanced_accuracy: 0.6357  |  0:07:36s\n",
      "epoch 373| loss: 0.30937 | val_0_accuracy: 0.61623 | val_0_balanced_accuracy: 0.61589 |  0:07:37s\n",
      "epoch 374| loss: 0.31685 | val_0_accuracy: 0.61169 | val_0_balanced_accuracy: 0.61216 |  0:07:38s\n",
      "epoch 375| loss: 0.3245  | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.61979 |  0:07:40s\n",
      "epoch 376| loss: 0.31306 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62005 |  0:07:41s\n",
      "epoch 377| loss: 0.32314 | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61673 |  0:07:42s\n",
      "epoch 378| loss: 0.36519 | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.6122  |  0:07:43s\n",
      "epoch 379| loss: 0.47608 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61737 |  0:07:45s\n",
      "epoch 380| loss: 0.45798 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.61968 |  0:07:46s\n",
      "epoch 381| loss: 0.41478 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.6227  |  0:07:47s\n",
      "epoch 382| loss: 0.38313 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61384 |  0:07:48s\n",
      "epoch 383| loss: 0.36555 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.62953 |  0:07:49s\n",
      "epoch 384| loss: 0.36329 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.61133 |  0:07:51s\n",
      "epoch 385| loss: 0.35169 | val_0_accuracy: 0.63896 | val_0_balanced_accuracy: 0.63959 |  0:07:52s\n",
      "epoch 386| loss: 0.33599 | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61686 |  0:07:53s\n",
      "epoch 387| loss: 0.32833 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61729 |  0:07:54s\n",
      "epoch 388| loss: 0.32514 | val_0_accuracy: 0.61623 | val_0_balanced_accuracy: 0.61745 |  0:07:56s\n",
      "epoch 389| loss: 0.31962 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62416 |  0:07:57s\n",
      "epoch 390| loss: 0.31201 | val_0_accuracy: 0.63377 | val_0_balanced_accuracy: 0.63503 |  0:07:58s\n",
      "epoch 391| loss: 0.30961 | val_0_accuracy: 0.63506 | val_0_balanced_accuracy: 0.63637 |  0:07:59s\n",
      "epoch 392| loss: 0.31301 | val_0_accuracy: 0.62922 | val_0_balanced_accuracy: 0.62999 |  0:08:00s\n",
      "epoch 393| loss: 0.31521 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62471 |  0:08:02s\n",
      "epoch 394| loss: 0.30759 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62953 |  0:08:03s\n",
      "epoch 395| loss: 0.30629 | val_0_accuracy: 0.61623 | val_0_balanced_accuracy: 0.61699 |  0:08:04s\n",
      "epoch 396| loss: 0.29988 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62575 |  0:08:05s\n",
      "epoch 397| loss: 0.29879 | val_0_accuracy: 0.62597 | val_0_balanced_accuracy: 0.62668 |  0:08:07s\n",
      "epoch 398| loss: 0.30295 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.6193  |  0:08:08s\n",
      "epoch 399| loss: 0.31101 | val_0_accuracy: 0.61104 | val_0_balanced_accuracy: 0.61086 |  0:08:09s\n",
      "epoch 400| loss: 0.29954 | val_0_accuracy: 0.61299 | val_0_balanced_accuracy: 0.61211 |  0:08:10s\n",
      "epoch 401| loss: 0.36545 | val_0_accuracy: 0.61753 | val_0_balanced_accuracy: 0.61875 |  0:08:11s\n",
      "epoch 402| loss: 0.35778 | val_0_accuracy: 0.62078 | val_0_balanced_accuracy: 0.62    |  0:08:13s\n",
      "epoch 403| loss: 0.32304 | val_0_accuracy: 0.62727 | val_0_balanced_accuracy: 0.6284  |  0:08:14s\n",
      "epoch 404| loss: 0.32206 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62504 |  0:08:15s\n",
      "epoch 405| loss: 0.30946 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62294 |  0:08:16s\n",
      "epoch 406| loss: 0.29979 | val_0_accuracy: 0.61104 | val_0_balanced_accuracy: 0.61048 |  0:08:17s\n",
      "epoch 407| loss: 0.29583 | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62316 |  0:08:19s\n",
      "epoch 408| loss: 0.29647 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60906 |  0:08:20s\n",
      "epoch 409| loss: 0.29473 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61611 |  0:08:21s\n",
      "epoch 410| loss: 0.29629 | val_0_accuracy: 0.5987  | val_0_balanced_accuracy: 0.59798 |  0:08:22s\n",
      "epoch 411| loss: 0.30009 | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62282 |  0:08:23s\n",
      "epoch 412| loss: 0.30688 | val_0_accuracy: 0.62013 | val_0_balanced_accuracy: 0.62034 |  0:08:25s\n",
      "epoch 413| loss: 0.29429 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.6107  |  0:08:26s\n",
      "epoch 414| loss: 0.29759 | val_0_accuracy: 0.58377 | val_0_balanced_accuracy: 0.58229 |  0:08:27s\n",
      "epoch 415| loss: 0.36645 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.60555 |  0:08:28s\n",
      "epoch 416| loss: 0.3335  | val_0_accuracy: 0.62208 | val_0_balanced_accuracy: 0.62143 |  0:08:29s\n",
      "epoch 417| loss: 0.31298 | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61635 |  0:08:31s\n",
      "epoch 418| loss: 0.30727 | val_0_accuracy: 0.61818 | val_0_balanced_accuracy: 0.61803 |  0:08:32s\n",
      "epoch 419| loss: 0.29852 | val_0_accuracy: 0.61429 | val_0_balanced_accuracy: 0.61333 |  0:08:33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 420| loss: 0.29766 | val_0_accuracy: 0.62403 | val_0_balanced_accuracy: 0.62576 |  0:08:34s\n",
      "epoch 421| loss: 0.29909 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.60268 |  0:08:36s\n",
      "epoch 422| loss: 0.29389 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61653 |  0:08:37s\n",
      "epoch 423| loss: 0.28868 | val_0_accuracy: 0.63052 | val_0_balanced_accuracy: 0.63062 |  0:08:38s\n",
      "epoch 424| loss: 0.29358 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.61016 |  0:08:39s\n",
      "epoch 425| loss: 0.32642 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.61027 |  0:08:40s\n",
      "epoch 426| loss: 0.30616 | val_0_accuracy: 0.61688 | val_0_balanced_accuracy: 0.61661 |  0:08:42s\n",
      "epoch 427| loss: 0.29766 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61607 |  0:08:43s\n",
      "epoch 428| loss: 0.32833 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61354 |  0:08:44s\n",
      "epoch 429| loss: 0.33837 | val_0_accuracy: 0.62857 | val_0_balanced_accuracy: 0.62847 |  0:08:45s\n",
      "epoch 430| loss: 0.31858 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61363 |  0:08:46s\n",
      "epoch 431| loss: 0.30359 | val_0_accuracy: 0.60325 | val_0_balanced_accuracy: 0.60314 |  0:08:48s\n",
      "epoch 432| loss: 0.29726 | val_0_accuracy: 0.61104 | val_0_balanced_accuracy: 0.61128 |  0:08:49s\n",
      "epoch 433| loss: 0.29337 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.61036 |  0:08:50s\n",
      "epoch 434| loss: 0.30087 | val_0_accuracy: 0.6026  | val_0_balanced_accuracy: 0.60239 |  0:08:51s\n",
      "epoch 435| loss: 0.29451 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61333 |  0:08:53s\n",
      "epoch 436| loss: 0.28881 | val_0_accuracy: 0.60519 | val_0_balanced_accuracy: 0.60664 |  0:08:54s\n",
      "epoch 437| loss: 0.30805 | val_0_accuracy: 0.61948 | val_0_balanced_accuracy: 0.62001 |  0:08:55s\n",
      "epoch 438| loss: 0.28877 | val_0_accuracy: 0.61883 | val_0_balanced_accuracy: 0.61908 |  0:08:56s\n",
      "epoch 439| loss: 0.29392 | val_0_accuracy: 0.60519 | val_0_balanced_accuracy: 0.60604 |  0:08:57s\n",
      "epoch 440| loss: 0.28612 | val_0_accuracy: 0.60584 | val_0_balanced_accuracy: 0.606   |  0:08:59s\n",
      "epoch 441| loss: 0.27821 | val_0_accuracy: 0.60325 | val_0_balanced_accuracy: 0.60302 |  0:09:00s\n",
      "epoch 442| loss: 0.29027 | val_0_accuracy: 0.62078 | val_0_balanced_accuracy: 0.62101 |  0:09:01s\n",
      "epoch 443| loss: 0.28687 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.60931 |  0:09:02s\n",
      "epoch 444| loss: 0.28142 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60927 |  0:09:03s\n",
      "epoch 445| loss: 0.28974 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60944 |  0:09:05s\n",
      "epoch 446| loss: 0.28749 | val_0_accuracy: 0.61104 | val_0_balanced_accuracy: 0.6112  |  0:09:06s\n",
      "epoch 447| loss: 0.26985 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61321 |  0:09:07s\n",
      "epoch 448| loss: 0.28155 | val_0_accuracy: 0.62273 | val_0_balanced_accuracy: 0.62239 |  0:09:08s\n",
      "epoch 449| loss: 0.28275 | val_0_accuracy: 0.60649 | val_0_balanced_accuracy: 0.60675 |  0:09:09s\n",
      "epoch 450| loss: 0.27463 | val_0_accuracy: 0.62468 | val_0_balanced_accuracy: 0.62449 |  0:09:11s\n",
      "epoch 451| loss: 0.29438 | val_0_accuracy: 0.61299 | val_0_balanced_accuracy: 0.61363 |  0:09:12s\n",
      "epoch 452| loss: 0.28984 | val_0_accuracy: 0.61883 | val_0_balanced_accuracy: 0.61925 |  0:09:13s\n",
      "epoch 453| loss: 0.29034 | val_0_accuracy: 0.60325 | val_0_balanced_accuracy: 0.60323 |  0:09:14s\n",
      "epoch 454| loss: 0.28568 | val_0_accuracy: 0.60779 | val_0_balanced_accuracy: 0.60666 |  0:09:15s\n",
      "epoch 455| loss: 0.28492 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61363 |  0:09:16s\n",
      "epoch 456| loss: 0.27891 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.60441 |  0:09:18s\n",
      "epoch 457| loss: 0.28138 | val_0_accuracy: 0.6     | val_0_balanced_accuracy: 0.59911 |  0:09:19s\n",
      "epoch 458| loss: 0.27196 | val_0_accuracy: 0.62792 | val_0_balanced_accuracy: 0.62751 |  0:09:20s\n",
      "epoch 459| loss: 0.29596 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60834 |  0:09:21s\n",
      "epoch 460| loss: 0.28148 | val_0_accuracy: 0.59805 | val_0_balanced_accuracy: 0.59773 |  0:09:22s\n",
      "epoch 461| loss: 0.27283 | val_0_accuracy: 0.59286 | val_0_balanced_accuracy: 0.59274 |  0:09:23s\n",
      "epoch 462| loss: 0.27858 | val_0_accuracy: 0.61494 | val_0_balanced_accuracy: 0.61468 |  0:09:25s\n",
      "epoch 463| loss: 0.27215 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.61083 |  0:09:26s\n",
      "epoch 464| loss: 0.27924 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61425 |  0:09:27s\n",
      "epoch 465| loss: 0.27397 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.60877 |  0:09:28s\n",
      "epoch 466| loss: 0.27292 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.61442 |  0:09:29s\n",
      "epoch 467| loss: 0.27943 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.60939 |  0:09:31s\n",
      "epoch 468| loss: 0.26748 | val_0_accuracy: 0.60325 | val_0_balanced_accuracy: 0.60281 |  0:09:32s\n",
      "epoch 469| loss: 0.27095 | val_0_accuracy: 0.61104 | val_0_balanced_accuracy: 0.61166 |  0:09:33s\n",
      "epoch 470| loss: 0.26991 | val_0_accuracy: 0.61234 | val_0_balanced_accuracy: 0.61229 |  0:09:34s\n",
      "epoch 471| loss: 0.26903 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.60297 |  0:09:35s\n",
      "epoch 472| loss: 0.28571 | val_0_accuracy: 0.60455 | val_0_balanced_accuracy: 0.6039  |  0:09:37s\n",
      "epoch 473| loss: 0.28089 | val_0_accuracy: 0.60519 | val_0_balanced_accuracy: 0.60592 |  0:09:38s\n",
      "epoch 474| loss: 0.2847  | val_0_accuracy: 0.60065 | val_0_balanced_accuracy: 0.60059 |  0:09:39s\n",
      "epoch 475| loss: 0.27034 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.60939 |  0:09:40s\n",
      "epoch 476| loss: 0.26904 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.60344 |  0:09:42s\n",
      "epoch 477| loss: 0.25893 | val_0_accuracy: 0.62532 | val_0_balanced_accuracy: 0.62567 |  0:09:43s\n",
      "epoch 478| loss: 0.26669 | val_0_accuracy: 0.60649 | val_0_balanced_accuracy: 0.60667 |  0:09:44s\n",
      "epoch 479| loss: 0.26234 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.60834 |  0:09:45s\n",
      "epoch 480| loss: 0.26984 | val_0_accuracy: 0.59481 | val_0_balanced_accuracy: 0.59349 |  0:09:47s\n",
      "epoch 481| loss: 0.26633 | val_0_accuracy: 0.60714 | val_0_balanced_accuracy: 0.6054  |  0:09:48s\n",
      "epoch 482| loss: 0.27193 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62139 |  0:09:49s\n",
      "epoch 483| loss: 0.26961 | val_0_accuracy: 0.61364 | val_0_balanced_accuracy: 0.61431 |  0:09:50s\n",
      "epoch 484| loss: 0.27155 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.61003 |  0:09:51s\n",
      "epoch 485| loss: 0.26917 | val_0_accuracy: 0.60325 | val_0_balanced_accuracy: 0.60226 |  0:09:52s\n",
      "epoch 486| loss: 0.25804 | val_0_accuracy: 0.60909 | val_0_balanced_accuracy: 0.60978 |  0:09:54s\n",
      "epoch 487| loss: 0.26147 | val_0_accuracy: 0.61558 | val_0_balanced_accuracy: 0.614   |  0:09:55s\n",
      "epoch 488| loss: 0.26471 | val_0_accuracy: 0.60065 | val_0_balanced_accuracy: 0.60206 |  0:09:56s\n",
      "epoch 489| loss: 0.27018 | val_0_accuracy: 0.61039 | val_0_balanced_accuracy: 0.61057 |  0:09:57s\n",
      "epoch 490| loss: 0.2665  | val_0_accuracy: 0.6013  | val_0_balanced_accuracy: 0.60155 |  0:09:58s\n",
      "epoch 491| loss: 0.26003 | val_0_accuracy: 0.61169 | val_0_balanced_accuracy: 0.61191 |  0:10:00s\n",
      "epoch 492| loss: 0.27242 | val_0_accuracy: 0.62143 | val_0_balanced_accuracy: 0.62156 |  0:10:01s\n",
      "epoch 493| loss: 0.26649 | val_0_accuracy: 0.60974 | val_0_balanced_accuracy: 0.60952 |  0:10:02s\n",
      "epoch 494| loss: 0.26703 | val_0_accuracy: 0.59091 | val_0_balanced_accuracy: 0.59107 |  0:10:03s\n",
      "epoch 495| loss: 0.26849 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.60721 |  0:10:04s\n",
      "epoch 496| loss: 0.26454 | val_0_accuracy: 0.60844 | val_0_balanced_accuracy: 0.60856 |  0:10:05s\n",
      "epoch 497| loss: 0.25483 | val_0_accuracy: 0.6039  | val_0_balanced_accuracy: 0.6036  |  0:10:07s\n",
      "epoch 498| loss: 0.2582  | val_0_accuracy: 0.59351 | val_0_balanced_accuracy: 0.59363 |  0:10:08s\n",
      "epoch 499| loss: 0.26612 | val_0_accuracy: 0.59351 | val_0_balanced_accuracy: 0.59371 |  0:10:09s\n",
      "Stop training because you reached max_epochs = 500 with best_epoch = 107 and best_val_0_balanced_accuracy = 0.66559\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier \n",
    "\n",
    "clf = TabNetMultiTaskClassifier() \n",
    "\n",
    "clf.fit(\n",
    "    X_train, Y_train, \n",
    "    eval_set=[(X_val, Y_val)], \n",
    "    eval_metric = ['accuracy', 'balanced_accuracy'],\n",
    "    max_epochs = 500, \n",
    "    patience = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.6259426847662142%\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(X_test)[0]\n",
    "cnt = 0 \n",
    "for i in range(len(Y_test)):\n",
    "    if float(prediction[i]) == Y_test[i][0]:\n",
    "        cnt += 1 \n",
    "\n",
    "print(\"accuracy = {}%\".format(cnt / len(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at tabnet_binary.pt.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tabnet_binary.pt.zip'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.save_model(\"tabnet_binary.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "always long accuracy = 50.301659125188536%\n",
      "always short accuracy = 49.698340874811464%\n",
      "random agent accuracy = 49.47209653092006%\n"
     ]
    }
   ],
   "source": [
    "# check against some baselines \n",
    "all_long = np.zeros((len(prediction))) \n",
    "all_short = np.ones((len(prediction))) \n",
    "random_agent = [random.randint(0,1) for i in range(len(prediction))] \n",
    "\n",
    "all_long_cnt = 0\n",
    "all_short_cnt = 0 \n",
    "random_cnt = 0 \n",
    "for i in range(len(Y_test)):\n",
    "    if all_long[i] == Y_test[i][0]:\n",
    "        all_long_cnt += 1 \n",
    "    if all_short[i] == Y_test[i][0]:\n",
    "        all_short_cnt += 1 \n",
    "    if random_agent[i] == Y_test[i][0]:\n",
    "        random_cnt += 1 \n",
    "    \n",
    "print(\"always long accuracy = {}%\".format(all_long_cnt / len(prediction) * 100)) \n",
    "print(\"always short accuracy = {}%\".format(all_short_cnt / len(prediction) * 100))\n",
    "print(\"random agent accuracy = {}%\".format(random_cnt / len(prediction) * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
